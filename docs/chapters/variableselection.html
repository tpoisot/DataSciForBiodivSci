<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.429">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science for Biodiversity Scientists - 6&nbsp; Variable selection and feature engineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": true,
  "collapse-after": 1,
  "panel-placement": "start",
  "type": "overlay",
  "limit": 10,
  "keyboard-shortcut": [
    null
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/variableselection.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Variable selection and feature engineering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Data Science for Biodiversity Scientists</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Data-Science-for-Biodiversity-Scientists.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Data-Science-for-Biodiversity-Scientists.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div id="quarto-search" class="quarto-navigation-tool px-1" title="Search"></div>
</div>
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/gradientdescent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Gradient descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/crossvalidation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Cross-validation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/variableselection.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Variable selection and feature engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/learningcurves.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Learning curves and moving thresholds</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Explaining predictions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-leakage" id="toc-sec-leakage" class="nav-link active" data-scroll-target="#sec-leakage"><span class="header-section-number">6.1</span> What is data leakage?</a>
  <ul class="collapse">
  <li><a href="#sec-leakage-consequences" id="toc-sec-leakage-consequences" class="nav-link" data-scroll-target="#sec-leakage-consequences"><span class="header-section-number">6.1.1</span> Consequences of data leakage</a></li>
  <li><a href="#sec-leakage-avoid" id="toc-sec-leakage-avoid" class="nav-link" data-scroll-target="#sec-leakage-avoid"><span class="header-section-number">6.1.2</span> Avoiding data leakage</a></li>
  </ul></li>
  <li><a href="#variable-selection" id="toc-variable-selection" class="nav-link" data-scroll-target="#variable-selection"><span class="header-section-number">6.2</span> Variable selection</a>
  <ul class="collapse">
  <li><a href="#sec-predictors-curse" id="toc-sec-predictors-curse" class="nav-link" data-scroll-target="#sec-predictors-curse"><span class="header-section-number">6.2.1</span> The curse of dimensionality</a></li>
  <li><a href="#step-wise-approaches-to-variable-selection" id="toc-step-wise-approaches-to-variable-selection" class="nav-link" data-scroll-target="#step-wise-approaches-to-variable-selection"><span class="header-section-number">6.2.2</span> Step-wise approaches to variable selection</a></li>
  <li><a href="#removal-of-colinear-variables" id="toc-removal-of-colinear-variables" class="nav-link" data-scroll-target="#removal-of-colinear-variables"><span class="header-section-number">6.2.3</span> Removal of colinear variables</a></li>
  </ul></li>
  <li><a href="#multivariate-transformations" id="toc-multivariate-transformations" class="nav-link" data-scroll-target="#multivariate-transformations"><span class="header-section-number">6.3</span> Multivariate transformations</a></li>
  <li><a href="#application-optimal-variables-for-the-sitta-whiteheadi-model" id="toc-application-optimal-variables-for-the-sitta-whiteheadi-model" class="nav-link" data-scroll-target="#application-optimal-variables-for-the-sitta-whiteheadi-model"><span class="header-section-number">6.4</span> Application: optimal variables for the <em>Sitta whiteheadi</em> model</a>
  <ul class="collapse">
  <li><a href="#variable-selection-1" id="toc-variable-selection-1" class="nav-link" data-scroll-target="#variable-selection-1"><span class="header-section-number">6.4.1</span> Variable selection</a></li>
  <li><a href="#variable-transformation" id="toc-variable-transformation" class="nav-link" data-scroll-target="#variable-transformation"><span class="header-section-number">6.4.2</span> Variable transformation</a></li>
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection"><span class="header-section-number">6.4.3</span> Model selection</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">6.5</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-predictors" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Variable selection and feature engineering</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In <a href="classification.html" class="quarto-xref"><span>Chapter&nbsp;5</span></a>, we introduced a simple classifier trained on a dataset of presence and pseudo-absences of a species (<em>Sitta whiteheadi</em>), which we predicted using the mean annual temperature as well as the annual total precipitation. This choice of variables was motivated by our knowledge of the fact that most species tend to have some temperature and precipitation they are best suited to. But we can approach the exercise of selecting predictive variables in a far more formal way, and this will form the core of this chapter. Specifically, we will examine two related techniques: variable selection, and feature engineering.</p>
<p>There are two reasons to think about variable selection and feature engineering – first, the variables we have may not all be predictive for the specific problem we are trying to solve; second, the variables may not be expressed in the correct “way” to solve our problem. This calls for a joint approach of selecting and transforming features. Before we do anything to our features (transformation or selection), we need to talk about data leakage.</p>
<section id="sec-leakage" class="level2 page-columns page-full" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="sec-leakage"><span class="header-section-number">6.1</span> What is data leakage?</h2>
<p>Data leakage is a concept that is, if you can believe it, grosser than it sounds.</p>
<p>The purpose of this section is to put the fear of data leakage in you, because it can, and most assuredly <em>will</em>, lead to bad models, which is to say (as we discussed in <a href="gradientdescent.html#sec-gradientdescent-trainedmodel" class="quarto-xref"><span>Section&nbsp;3.1</span></a>), models that do not adequately represent the underlying data, in part because we have built-in some biases into them. In turn, this can eventually lead to decreased explainability of the models, which erodes trust in their predictions <span class="citation" data-cites="amarasinghe2023">(<a href="../references.html#ref-amarasinghe2023" role="doc-biblioref">Amarasinghe <em>et al.</em> 2023</a>)</span>. As illustrated by <span class="citation" data-cites="stock2023">Stock <em>et al.</em> (<a href="../references.html#ref-stock2023" role="doc-biblioref">2023</a>)</span>, a large number of ecological applications of machine learning are particularly susceptible to data leakage, meaning that this should be a core point of concern for us.</p>
<section id="sec-leakage-consequences" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="sec-leakage-consequences"><span class="header-section-number">6.1.1</span> Consequences of data leakage</h3>
<p>We take data leakage so seriously because it is one of the top ten mistakes in applied machine learning <span class="citation" data-cites="nisbet2018">(<a href="../references.html#ref-nisbet2018" role="doc-biblioref">Nisbet <em>et al.</em> 2018</a>)</span>. Data leakage happens information “leaks” from the training conditions to the evaluation conditions; in other words, when the model is evaluated after mistakenly being fed information that would not be available in real-life situations. Note that this definition of leakage is different from another notion, namely the loss of data availability over time <span class="citation" data-cites="Peterson2018">(<a href="../references.html#ref-Peterson2018" role="doc-biblioref">Peterson <em>et al.</em> 2018</a>)</span>.</p>
<p>It is worth stopping for a moment to consider what these “real-life situations” are, and how they differ from the training of the model. Most of this difference can be summarized by the fact that when we are <em>applying</em> a model, we can start from the model <em>only</em>. Which is to say, the data that have been used for the training and validation of the model may have been lost, without changing the applicability of the model: it works on entirely new data. We have discussed this situation in <a href="crossvalidation.html#sec-crossvalidation-testing" class="quarto-xref"><span>Section&nbsp;4.1.3</span></a>: the test of a model is conducted on data that have never been used for training, because we want to evaluate its performance in the conditions where it will be applied.</p>
<p>Because this is the behavior we want to simulate with a validation dataset, it is very important to fully disconnect the testing data from the rest of the data. We can illustrate this with an example. Let’s say we want to work on a time series of population size, such as provided by the <em>BioTIME</em> project <span class="citation" data-cites="dornelas2018">(<a href="../references.html#ref-dornelas2018" role="doc-biblioref">Dornelas <em>et al.</em> 2018</a>)</span>. One naïve approach would be to split this the time series at random into three datasets. We can use one to train the models, one to validate these models, and a last one for testing.</p>
<p>Congratulations! We have created data leakage! Because we are splitting our time series at random, the model will likely have been trained using data that date from <em>after</em> the start of the validation dataset. In other words: our model can peek into the future. This is highly unlikely to happen in practice, due to the laws of physics. A strategy that would prevent leakage would have been to pick a cut-off date to define the validation dataset, and then to decide how to deal with the training and testing sets.</p>
</section>
<section id="sec-leakage-avoid" class="level3 page-columns page-full" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="sec-leakage-avoid"><span class="header-section-number">6.1.2</span> Avoiding data leakage</h3>
<p>The most common advice given in order to prevent data leakage is the “learn/predict separation” <span class="citation" data-cites="kaufman2011">(<a href="../references.html#ref-kaufman2011" role="doc-biblioref">Kaufman <em>et al.</em> 2011</a>)</span>. Simply put, this means that whatever happens to the data used for training cannot be <em>simultaneously</em> applied to the data used for testing (or validation).</p>
<p>Assume that we want to transform our data using a Principal Component Analysis (PCA; <span class="citation" data-cites="pearson1901">Pearson (<a href="../references.html#ref-pearson1901" role="doc-biblioref">1901</a>)</span>). Ecologists often think of PCA as a technique to explore data <span class="citation" data-cites="legendre2012">(<a href="../references.html#ref-legendre2012" role="doc-biblioref">Legendre &amp; Legendre 2012</a>)</span>, but it is so much more than that! PCA is a model, because we can derive, from the data, a series of weights (in the transformation matrix), which we can then apply to other datasets in order to project them in the space of the projection of the training data.</p>
<p>If we have a dataset <span class="math inline">\(\mathbf{X}\)</span>, which we split into two components <span class="math inline">\(\mathbf{X}_0\)</span> for training ,and <span class="math inline">\(\mathbf{X}_1\)</span> for validation, there are two ways to use a PCA to transform these data. The first is <span class="math inline">\(\mathbf{T} = \mathbf{X}\mathbf{W}\)</span>, which uses the full dataset. When we predict the position of the validation data, we could use the transformation <span class="math inline">\(\mathbf{T}_1 = \mathbf{X}_1\mathbf{W}\)</span>, but this would introduce data leakage: we have trained the transformation we apply to <span class="math inline">\(\mathbf{X}_1\)</span> using data that are already in <span class="math inline">\(\mathbf{X}_1\)</span>, and therefore we have not respected the learn/predict separation. This mistake is extremely common in the species distribution literature <span class="citation" data-cites="demarco2018">(see <em>e.g.</em> <a href="../references.html#ref-demarco2018" role="doc-biblioref">De Marco &amp; Nóbrega 2018</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="../diagrams/data-leakage.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Overview of a data transformation pipeline that introduces data leakage (left), or that does not introduce data leakage (right). In both cases, a transformation such as a PCA is applied to the data; in the example on the right, it is applied as part of the model, and can therefore be applied without breaking the train/predict separation. The pipeline on the left introduces data leakage, as the training data will be changed by information contained in the validation data.</figcaption>
</figure>
</div>
<p>The second (correct) way to handle this situation is to perform our PCA using <span class="math inline">\(\mathbf{T}_0 = \mathbf{X}_0\mathbf{W}_0\)</span>, which is to say, the weights of our PCA are derived <em>only</em> from the training data. In this situation, whenever we project the data in the validation set using <span class="math inline">\(\mathbf{T}_1 = \mathbf{X}_1\mathbf{W}_0\)</span>, we respect the learn/predict separation: the transformation of <span class="math inline">\(\mathbf{X}_1\)</span> is entirely independent from the data contained in <span class="math inline">\(\mathbf{X}_1\)</span>. This is illustrated in <span class="quarto-unresolved-ref">?fig-predictors-leakage</span>.</p>
<section id="how-to-work-in-practice" class="level4" data-number="6.1.2.1">
<h4 data-number="6.1.2.1" class="anchored" data-anchor-id="how-to-work-in-practice"><span class="header-section-number">6.1.2.1</span> How to work in practice?</h4>
<p>Although avoiding data leakage is a tricky problem, there is a very specific mindset we can adopt that goes a long way towards not introducing it in our analyses, and it is as follows: <em>every data transformation step is a modeling step that is part of the learning process</em>. We do not, for example, apply a PCA and train the model on the projected variables – we feed raw data into a model, the first step of which is to perform this PCA for us.</p>
<p>This approach works because everything that can be represented as numbers is a model that can be trained.</p>
<p>If you want to transform a variable using the z-score, this is a model! It has two parameters that you can learn from the data, <span class="math inline">\(\mu\)</span> (the average of the variable) and <span class="math inline">\(\sigma\)</span> (its standard deviation). You can apply it to a data point <span class="math inline">\(y\)</span> with <span class="math inline">\(\hat y = (y - \mu)\sigma^{-1}\)</span>. Because this is a model, we need a dataset to learn these parameters from, and because we want to maintain the learn/predict separation, we will use the train dataset to get the values of <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\sigma_0\)</span>. This way, when we want to get the z-score of a new observation, for example from the testing dataset, we can get it using <span class="math inline">\(\hat y_1 = (y_1 - \mu_0)\sigma_0^{-1}\)</span>. The data transformation is entirely coming from information that was part of the training set.</p>
<p>One way to get the learn/predict transformation stupendously wrong is to transform our validation, testing, or prediction data using <span class="math inline">\(\hat y_1 = (y_1 - \mu_1)\sigma_1^{-1}\)</span>. This can be easily understood with an example. Assume that the variable <span class="math inline">\(y_0\)</span> is the temperature in our training dataset. We are interested in making a prediction in a world that is 2 degrees hotter, uniformly, which is to say that for whatever value of <span class="math inline">\(y_0\)</span>, the corresponding data point we use for prediction is <span class="math inline">\(y_1 = y_0 + 2\)</span>. If we take the z-score of this new value based on its own average and standard deviation, a temperature two degrees warmer in the prediction data will have the same z-score as its original value, or in other words, we have hidden the fact that there is a change in our predictors!</p>
<p>Treating the data preparation step as a part of the learning process, which is to say that we learn every transformation on the training set, and retain this transformation as part of the prediction process, we are protecting ourselves against both data leakage <em>and</em> the hiding of relevant changes in our predictors.</p>
</section>
</section>
</section>
<section id="variable-selection" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="variable-selection"><span class="header-section-number">6.2</span> Variable selection</h2>
<section id="sec-predictors-curse" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="sec-predictors-curse"><span class="header-section-number">6.2.1</span> The curse of dimensionality</h3>
<p>The number of variables we use for prediction is the number of dimensions of a problem. It would be tempting to say that adding dimensions should improve our chances to find a feature alongside which the classes become linearly separable. If only!</p>
<p>The “curse of dimensionality” is the common term of everything breaking down when the dimensions of a problem increase. In our perspective, where we rely on the resemblance between features to make a prediction, increasing the dimensions of a problem means adding features, and it has important consequences on the distance between observations. Picture two points positioned at random on the unit interval: the average distance between them is 1/3. If we add one dimension, keeping two points but turning this line into a cube, the average distance would be about 1/2. For a cube, about 2/3. For <span class="math inline">\(n\)</span> dimensions, we can figure out that the average distance grows like <span class="math inline">\(\sqrt{n/6 + c}\)</span>, which is to say that when we add more dimensions, we make the average distance between two points go to infinity. This effect is also affecting ecological studies <span class="citation" data-cites="smith2017">(<em>e.g.</em> <a href="../references.html#ref-smith2017" role="doc-biblioref">Smith <em>et al.</em> 2017</a>)</span>.</p>
<p>Therefore, we need to approach the problem of “which variables to use” with a specific mindset: we want a lot of information for our model, but not so much that the space in which the predictors exist turns immense. There are techniques for this.</p>
</section>
<section id="step-wise-approaches-to-variable-selection" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="step-wise-approaches-to-variable-selection"><span class="header-section-number">6.2.2</span> Step-wise approaches to variable selection</h3>
<p>In order to try and decrease the dimensionality of a problem, we can attempt to come up with a method to decide which variables to include, or to remove, from a model. This practice is usually called “stepwise” selection, and is the topic of <em>intense</em> debate in ecology, although several studies point to the fact that there is rarely a best technique to select variables <span class="citation" data-cites="murtaugh2009">(<a href="../references.html#ref-murtaugh2009" role="doc-biblioref">Murtaugh 2009</a>)</span>, that the same data can usually be adequately described by competing models <span class="citation" data-cites="whittingham2006">(<a href="../references.html#ref-whittingham2006" role="doc-biblioref">WHITTINGHAM <em>et al.</em> 2006</a>)</span>, and that classifiers can show high robustness to the inclusion of non-informative variables <span class="citation" data-cites="fox2017">(<a href="../references.html#ref-fox2017" role="doc-biblioref">Fox <em>et al.</em> 2017</a>)</span>. Situations in which variable selection has been shown top be useful is the case of model transfer <span class="citation" data-cites="petitpierre2016">(<a href="../references.html#ref-petitpierre2016" role="doc-biblioref">Petitpierre <em>et al.</em> 2016</a>)</span>, or (when informed by ecological knowledge), the demonstration that classes of variables had no measurable impact on model performance <span class="citation" data-cites="thuiller2004">(<a href="../references.html#ref-thuiller2004" role="doc-biblioref">Thuiller <em>et al.</em> 2004</a>)</span>.</p>
<p>Why, so, should we select the variables we put in our models?</p>
<p>The answer is simple: we seek to solve a specific problem in an optimal way, where “optimal” refers to the maximization of a performance measure we decided upon <em>a priori</em>. In our case, this is the MCC. Therefore, an ideal set of predictors is the one that, given our cross-validation strategy, maximizes our measure of performance.</p>
<p>In forward selection, assuming that we have <span class="math inline">\(f\)</span> features, we start by building <span class="math inline">\(f\)</span> models, each using one feature. For example, using the BioClim variables, <span class="math inline">\(m_1\)</span> would be attempting to predict presences and absences based only on temperature. Out of these models, we retain the variable given by <span class="math inline">\(\text{argmax}_f \text{MCC}(m_f)\)</span>, where <span class="math inline">\(\text{MCC}(m_f)\)</span> is the average value of MCC for the <span class="math inline">\(f\)</span>-th model on the validation datasets. This is the first variable we add to our set of selected variables. We then train <span class="math inline">\(f-1\)</span> models, and then again add the variable that leads to the best possible <em>increase</em> in the average value of the MCC. When we cannot find a remaining variable that would increase the performance of the model, we stop the process, and return the optimal set of variables. Forward selection can be constrained by, instead of starting from variables one by one, starting from a pre-selected set of variables that will always be included in the model.</p>
<p>There are two important things to consider here. First, the set of variables is only optimal under the assumptions of the stepwise selection process: the first variable is the one that boosts the predictive value of the model the most <em>on its own</em>, and the next variables <em>in the context of already selected variables</em>. Second, the variables are evaluated on the basis of their ability to <em>improve the performance of the model</em>; this does not imply that they are relevant to the ecological processes hapenning in the dataset. Infering mechanisms on the basis of variable selection if foolish.</p>
<p>The opposite of forward selection is backward selection, in which we start from a complete set of variables, then remove the one with the <em>worst</em> impact on model performance, and keep proceeding until we cannot remove a variable without making the model worse. The set of variables that remain will be the optimal set of variables. In almost no cases will forward and backward selection agree on which set of variables is the best – we have to settle this debate by either picking the model with the least parameters (the most parsimonious), or the one with the best performance.</p>
<p>Why not evaluate all the combination of variables?</p>
<p>Keep in mind that we do not know the number of variables we should use; therefore, for the 19 BioClim variables, we would have to evaluate <span class="math inline">\(\sum_f \binom{19}{f}\)</span>, which turns out to be an <em>immense</em> quantity (for example, <span class="math inline">\(\binom{19}{9}=92378\)</span>). For this reason, a complete enumeration of all variable combinations would be extremely wasteful.</p>
</section>
<section id="removal-of-colinear-variables" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="removal-of-colinear-variables"><span class="header-section-number">6.2.3</span> Removal of colinear variables</h3>
<p>Co-linearity of variables is challenging for all types of ecological models <span class="citation" data-cites="graham2003">(<a href="../references.html#ref-graham2003" role="doc-biblioref">Graham 2003</a>)</span>. In the case of species distribution models <span class="citation" data-cites="demarco2018">(<a href="../references.html#ref-demarco2018" role="doc-biblioref">De Marco &amp; Nóbrega 2018</a>)</span>, the variables are expected to be strongly auto-correlated, both because they have innate spatial auto-correlation, and because they are derived from a smaller set of raw data <span class="citation" data-cites="dormann2012">(<a href="../references.html#ref-dormann2012" role="doc-biblioref">Dormann <em>et al.</em> 2012</a>)</span>. For this reason, it is a</p>
</section>
</section>
<section id="multivariate-transformations" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="multivariate-transformations"><span class="header-section-number">6.3</span> Multivariate transformations</h2>
<p>Delicious. Finally some good fucking quantitative ecology.</p>
<p>PCA (also does dimensionality reduction)</p>
<p>One advantage of PCA is that it serves both as a way to remove colinearity, in that the principal components are orthogonal, and as a way to reduce the dimensionality of the problem as long as we decide on a threshold on the proportion of variance explained, and only retain the number of principal components needed to reach this threshold.</p>
<p>Whitening</p>
</section>
<section id="application-optimal-variables-for-the-sitta-whiteheadi-model" class="level2 page-columns page-full" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="application-optimal-variables-for-the-sitta-whiteheadi-model"><span class="header-section-number">6.4</span> Application: optimal variables for the <em>Sitta whiteheadi</em> model</h2>
<p>Before we start, we can re-establish the baseline performance of the model from <a href="classification.html" class="quarto-xref"><span>Chapter&nbsp;5</span></a>. In this (and the next) chapters, we will perform k-folds cross-validation (see <a href="crossvalidation.html#sec-crossvalidation-kfolds" class="quarto-xref"><span>Section&nbsp;4.3.4</span></a> for a refresher), using <span class="math inline">\(k=15\)</span>. This strategy gives an average MCC of 0.76, which represents our “target”: any model with a higher MCC will be “better” according to our criteria.</p>
<p>In a sense, this initial model was <em>already</em> coming from a variable selection process, only we did not use a quantitative criteria to include variables. And so, it is a good idea to evaluate whether our model was worse than a model including <em>all</em> the variables. Running the NBC again using all 19 BioClim variables, we get an average MCC on the validation data of 0.794. This is a small increase, but an increase nevertheless – our dataset had information that was not captured by temperature and precipitation.</p>
<p>In this section, we will start by evaluating the efficiency of different approaches to variable selection, then of variable transformation, then merge these two together to provide a model that is optimal with regards to the training data we have. In order to evaluate the model, we will maintain the use of the MCC; in addition, we will report the PPV and NPV (like in <a href="classification.html" class="quarto-xref"><span>Chapter&nbsp;5</span></a>).</p>
<section id="variable-selection-1" class="level3 page-columns page-full" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="variable-selection-1"><span class="header-section-number">6.4.1</span> Variable selection</h3>
<div id="tbl-predictors-selection" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="table quarto-float-caption quarto-float-tbl" id="tbl-predictors-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6.1: Consequences of different variable selection approaches on the performance of the model
</figcaption>
<div aria-describedby="tbl-predictors-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Model version</th>
<th>Variables</th>
<th>MCC</th>
<th>PPV</th>
<th>NPV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temperature, precipitation</td>
<td>2</td>
<td>0.76</td>
<td>0.901</td>
<td>0.859</td>
</tr>
<tr class="even">
<td>All variables</td>
<td>19</td>
<td>0.794</td>
<td>0.922</td>
<td>0.859</td>
</tr>
<tr class="odd">
<td>Backward selection</td>
<td>9</td>
<td>0.846</td>
<td>0.944</td>
<td>0.859</td>
</tr>
<tr class="even">
<td>Forward selection</td>
<td>6</td>
<td>0.848</td>
<td>0.946</td>
<td>0.859</td>
</tr>
<tr class="odd">
<td>Forward selection with temperature and precipitation</td>
<td>8</td>
<td>0.83</td>
<td>0.94</td>
<td>0.888</td>
</tr>
<tr class="even">
<td>Variance Inflation Factor</td>
<td>2</td>
<td>0.466</td>
<td>0.708</td>
<td>0.793</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Based on the results presented in <strong>TBL</strong>, the model trained on variables selected using forward selection gave the best results.</p>
<div id="cell-fig-predictors-rangediff" class="cell page-columns page-full" data-execution_count="9">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="12">
<div id="fig-predictors-rangediff" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-predictors-rangediff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="variableselection_files/figure-html/fig-predictors-rangediff-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig margin-caption" id="fig-predictors-rangediff-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6.1: Consequences of using the model with forward selection of variables on the predicted range of <em>Sitta whiteheadi</em>. The negative values represent range that was predicted by the original model but is not predicted by the optimized model, while the positive values represent new predictions. It is reinsuring to see that the overwhelming majority of the range is shared by both models.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="variable-transformation" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="variable-transformation"><span class="header-section-number">6.4.2</span> Variable transformation</h3>
<div id="e4b2d299" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>Cp0v, Cp0t <span class="op">=</span> <span class="fu">crossvalidate</span>(naivebayes, trainlabels, trainfeatures[<span class="op">:</span>,c0], folds; transformation<span class="op">=</span><span class="cn">nothing</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="pp">@info</span> <span class="fu">mean</span>(<span class="fu">mcc</span>.(Cp0v))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[ Info: 0.8296279028400423</code></pre>
</div>
</div>
</section>
<section id="model-selection" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="model-selection"><span class="header-section-number">6.4.3</span> Model selection</h3>
</section>
</section>
<section id="conclusion" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">6.5</span> Conclusion</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-amarasinghe2023" class="csl-entry" role="listitem">
Amarasinghe, K., Rodolfa, K.T., Lamba, H. &amp; Ghani, R. (2023). <a href="https://doi.org/10.1017/dap.2023.2">Explainable machine learning for public policy: Use cases, gaps, and research directions</a>. <em>Data &amp; Policy</em>, 5.
</div>
<div id="ref-demarco2018" class="csl-entry" role="listitem">
De Marco, P. &amp; Nóbrega, C.C. (2018). <a href="https://doi.org/10.1371/journal.pone.0202403">Evaluating collinearity effects on species distribution models: An approach based on virtual species simulation</a>. <em>PLOS ONE</em>, 13, e0202403.
</div>
<div id="ref-dormann2012" class="csl-entry" role="listitem">
Dormann, C.F., Elith, J., Bacher, S., Buchmann, C., Carl, G., Carré, G., <em>et al.</em> (2012). <a href="https://doi.org/10.1111/j.1600-0587.2012.07348.x">Collinearity: a review of methods to deal with it and a simulation study evaluating their performance</a>. <em>Ecography</em>, 36, 27–46.
</div>
<div id="ref-dornelas2018" class="csl-entry" role="listitem">
Dornelas, M., Antão, L.H., Moyes, F., Bates, A.E., Magurran, A.E., Adam, D., <em>et al.</em> (2018). <a href="https://doi.org/10.1111/geb.12729">BioTIME: A database of biodiversity time series for the Anthropocene</a>. <em>Global Ecology and Biogeography</em>, 27, 760–786.
</div>
<div id="ref-fox2017" class="csl-entry" role="listitem">
Fox, E.W., Hill, R.A., Leibowitz, S.G., Olsen, A.R., Thornbrugh, D.J. &amp; Weber, M.H. (2017). <a href="https://doi.org/10.1007/s10661-017-6025-0">Assessing the accuracy and stability of variable selection methods for random forest modeling in ecology</a>. <em>Environmental Monitoring and Assessment</em>, 189.
</div>
<div id="ref-graham2003" class="csl-entry" role="listitem">
Graham, M.H. (2003). <a href="https://doi.org/10.1890/02-3114">CONFRONTING MULTICOLLINEARITY IN ECOLOGICAL MULTIPLE REGRESSION</a>. <em>Ecology</em>, 84, 2809–2815.
</div>
<div id="ref-kaufman2011" class="csl-entry" role="listitem">
Kaufman, S., Rosset, S. &amp; Perlich, C. (2011). <a href="https://doi.org/10.1145/2020408.2020496">Leakage in data mining</a>. <em>Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</em>.
</div>
<div id="ref-legendre2012" class="csl-entry" role="listitem">
Legendre, P. &amp; Legendre, L. (2012). <em>Numerical ecology</em>. Developments in environmental modelling. Third English edition. Elsevier, Oxford, UK.
</div>
<div id="ref-murtaugh2009" class="csl-entry" role="listitem">
Murtaugh, P.A. (2009). <a href="https://doi.org/10.1111/j.1461-0248.2009.01361.x">Performance of several variable<span>-</span>selection methods applied to real ecological data</a>. <em>Ecology Letters</em>, 12, 1061–1068.
</div>
<div id="ref-nisbet2018" class="csl-entry" role="listitem">
Nisbet, R., Miner, G., Yale, K., Elder, J.F. &amp; Peterson, A.F. (2018). <em>Handbook of statistical analysis and data mining applications</em>. Second edition. Academic Press, London.
</div>
<div id="ref-pearson1901" class="csl-entry" role="listitem">
Pearson, K. (1901). <a href="https://doi.org/10.1080/14786440109462720">LIII. <span><em>On lines and planes of closest fit to systems of points in space</em></span></a>. <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em>, 2, 559–572.
</div>
<div id="ref-Peterson2018" class="csl-entry" role="listitem">
Peterson, A.T., Asase, A., Canhos, D., Souza, S. de &amp; Wieczorek, J. (2018). <a href="https://doi.org/10.3897/bdj.6.e26826">Data leakage and loss in biodiversity informatics</a>. <em>Biodiversity Data Journal</em>, 6.
</div>
<div id="ref-petitpierre2016" class="csl-entry" role="listitem">
Petitpierre, B., Broennimann, O., Kueffer, C., Daehler, C. &amp; Guisan, A. (2016). <a href="https://doi.org/10.1111/geb.12530">Selecting predictors to maximize the transferability of species distribution models: lessons from cross<span>-</span>continental plant invasions</a>. <em>Global Ecology and Biogeography</em>, 26, 275–287.
</div>
<div id="ref-smith2017" class="csl-entry" role="listitem">
Smith, M.L., Ruffley, M., Espíndola, A., Tank, D.C., Sullivan, J. &amp; Carstens, B.C. (2017). <a href="https://doi.org/10.1111/mec.14223">Demographic model selection using random forests and the site frequency spectrum</a>. <em>Molecular Ecology</em>, 26, 4562–4573.
</div>
<div id="ref-stock2023" class="csl-entry" role="listitem">
Stock, A., Gregr, E.J. &amp; Chan, K.M.A. (2023). <a href="https://doi.org/10.1038/s41559-023-02162-1">Data leakage jeopardizes ecological applications of machine learning</a>. <em>Nature Ecology &amp; Evolution</em>.
</div>
<div id="ref-thuiller2004" class="csl-entry" role="listitem">
Thuiller, W., Araújo, M.B. &amp; Lavorel, S. (2004). <a href="https://doi.org/10.1046/j.0305-0270.2003.00991.x">Do we need land<span>-</span>cover data to model species distributions in Europe?</a> <em>Journal of Biogeography</em>, 31, 353–361.
</div>
<div id="ref-whittingham2006" class="csl-entry" role="listitem">
WHITTINGHAM, M.J., STEPHENS, P.A., BRADBURY, R.B. &amp; FRECKLETON, R.P. (2006). <a href="https://doi.org/10.1111/j.1365-2656.2006.01141.x">Why do we still use stepwise modelling in ecology and behaviour?</a> <em>Journal of Animal Ecology</em>, 75, 1182–1189.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work is licensed under the <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International License</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>