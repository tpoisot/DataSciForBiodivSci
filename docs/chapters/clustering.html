<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Clustering – Machine Learning for Biodiversity Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": true,
  "collapse-after": 2,
  "panel-placement": "start",
  "type": "overlay",
  "limit": 10,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/clustering.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Clustering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning for Biodiversity Scientists</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/tpoisot/MLBS" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../Machine-Learning-for-Biodiversity-Scientists.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div id="quarto-search" class="quarto-navigation-tool px-1" title="Search"></div>
</div>
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/clustering.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/gradientdescent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Gradient descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/crossvalidation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Cross-validation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/variableselection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Variable preparation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/learningcurves.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Hyper-parameters tuning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Explaining predictions</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/instructornotes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Instructor notes</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="-1">
    <h2 id="toc-title">Chapter overview</h2>
   
  <ul>
  <li><a href="#a-digression-which-birds-are-red" id="toc-a-digression-which-birds-are-red" class="nav-link active" data-scroll-target="#a-digression-which-birds-are-red"><span class="header-section-number">2.1</span> A digression: which birds are red?</a></li>
  <li><a href="#the-problem-classifying-pixels-from-an-image" id="toc-the-problem-classifying-pixels-from-an-image" class="nav-link" data-scroll-target="#the-problem-classifying-pixels-from-an-image"><span class="header-section-number">2.2</span> The problem: classifying pixels from an image</a></li>
  <li><a href="#the-theory-behind-k-means-clustering" id="toc-the-theory-behind-k-means-clustering" class="nav-link" data-scroll-target="#the-theory-behind-k-means-clustering"><span class="header-section-number">2.3</span> The theory behind <em>k</em>-means clustering</a>
  <ul class="collapse">
  <li><a href="#inputs-and-parameters" id="toc-inputs-and-parameters" class="nav-link" data-scroll-target="#inputs-and-parameters"><span class="header-section-number">2.3.1</span> Inputs and parameters</a></li>
  <li><a href="#assigning-instances-to-classes" id="toc-assigning-instances-to-classes" class="nav-link" data-scroll-target="#assigning-instances-to-classes"><span class="header-section-number">2.3.2</span> Assigning instances to classes</a></li>
  <li><a href="#optimizing-the-centroids" id="toc-optimizing-the-centroids" class="nav-link" data-scroll-target="#optimizing-the-centroids"><span class="header-section-number">2.3.3</span> Optimizing the centroids</a></li>
  <li><a href="#updating-the-classes" id="toc-updating-the-classes" class="nav-link" data-scroll-target="#updating-the-classes"><span class="header-section-number">2.3.4</span> Updating the classes</a></li>
  <li><a href="#sec-clustering-optimality" id="toc-sec-clustering-optimality" class="nav-link" data-scroll-target="#sec-clustering-optimality"><span class="header-section-number">2.3.5</span> Identification of the optimal number of clusters</a></li>
  </ul></li>
  <li><a href="#application-optimal-clustering-of-the-satellite-image-data" id="toc-application-optimal-clustering-of-the-satellite-image-data" class="nav-link" data-scroll-target="#application-optimal-clustering-of-the-satellite-image-data"><span class="header-section-number">2.4</span> Application: optimal clustering of the satellite image data</a>
  <ul class="collapse">
  <li><a href="#sec-kmeans-initial" id="toc-sec-kmeans-initial" class="nav-link" data-scroll-target="#sec-kmeans-initial"><span class="header-section-number">2.4.1</span> Initial run</a></li>
  <li><a href="#optimal-number-of-pixels" id="toc-optimal-number-of-pixels" class="nav-link" data-scroll-target="#optimal-number-of-pixels"><span class="header-section-number">2.4.2</span> Optimal number of pixels</a></li>
  <li><a href="#clustering-with-optimal-number-of-classes" id="toc-clustering-with-optimal-number-of-classes" class="nav-link" data-scroll-target="#clustering-with-optimal-number-of-classes"><span class="header-section-number">2.4.3</span> Clustering with optimal number of classes</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">2.5</span> Conclusion</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/tpoisot/MLBS/blob/main/chapters/clustering.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/tpoisot/MLBS/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-clustering" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Clustering</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>As we mentioned in the introduction, a core idea of data science is that things that look the same (in that, when described with data, they resemble one another) are likely to be the same. Although this sounds like a simplifying assumption, this can provide the basis for approaches in which we <em>create</em> groups in data that have no labels. This task is called clustering: we seek to add a <em>label</em> to each observation, in order to form groups, and the data we work from do <em>not</em> have a label that we can use to train a model. In this chapter, we will explore the <em>k</em>-means algorithm for clustering, and illustrate how it can be used in practice.</p>
<section id="a-digression-which-birds-are-red" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="a-digression-which-birds-are-red"><span class="header-section-number">2.1</span> A digression: which birds are red?</h2>
<p>Before diving in, it is a good idea to ponder a simple case. We can divide everything in just two categories: things with red feathers, and things without red feathers. An example of a thing with red feathers is the Northern Cardinal (<em>Cardinalis cardinalis</em>), and things without red feathers are the iMac G3, Haydn’s string quartets, and of course the Northern Cardinal (<em>Cardinalis cardinalis</em>).</p>
<p>See, biodiversity data science is complicated, because it tends to rely on the assumption that we can categorize the natural world, and the natural world (mostly in response to natural selection) comes up with ways to be, well, diverse and hard to categorize. In the Northern Cardinal, this is shown in males having red feathers, and females having mostly brown feathers. Before moving forward, we need to consider ways to solve this issue, as this issue will come up <em>all the time.</em></p>
<p>The first mistake we have made is that the scope of objects we want to classify, which we will describe as the “domain” of our classification, is much too broad: there are few legitimate applications where we will have a dataset with Northern Cardinals, iMac G3s, and Haydn’s string quartets. Picking a reasonable universe of classes would have solved our problem a little. For example, among the things that do not have red feathers are the Mourning Dove, the Kentucky Warbler, and the House Sparrow.</p>
<p>The second mistake that we have made is improperly defining our classes; bird species exhibit sexual dimorphism (not in an interesting way, like wrasses, but let’s give them some credit for trying). Assuming that there is such a thing as <em>a</em> Northern Cardinal is not necessarily a reasonable assumption! And yet, the assumption that a single label is a valid representation of non-monomorphic populations is a surprisingly common one, with actual consequences for the performance of image classification algorithms <span class="citation" data-cites="luccioni2023">(<a href="#ref-luccioni2023" role="doc-biblioref">Luccioni &amp; Rolnick 2023</a>)</span>. This assumption reveals a lot about our biases: male specimens are over-represented in museum collections, for example <span class="citation" data-cites="cooper2019">(<a href="#ref-cooper2019" role="doc-biblioref">Cooper <em>et al.</em> 2019</a>)</span>. In a lot of species, we would need to split the taxonomic unit into multiple groups in order to adequately describe them.</p>
<p>The third mistake we have made is using predictors that are too vague. The “presence of red feathers” is not a predictor that can easily discriminate between the Northen Cardinal (yes for males, sometimes for females), the House Finch (a little for males, no for females), and the Red-Winged Black Bird (a little for males, no for females). In fact, it cannot really capture the difference between red feathers for the male House Finch (head and breast) and the male Red Winged Black Bird (wings, as the name suggests).</p>
<p>The final mistake we have made is in assuming that “red” is relevant as a predictor. In a wonderful paper, <span class="citation" data-cites="cooney2022">Cooney <em>et al.</em> (<a href="#ref-cooney2022" role="doc-biblioref">2022</a>)</span> have converted the color of birds into a bird-relevant colorimetric space, revealing a clear latitudinal trend in the ways bird colors, as perceived by other birds, are distributed. This analysis, incidentally, splits all species into males and females. The use of a color space that accounts for the way colors are perceived is a fantastic example of why data science puts domain knowledge front and center.</p>
<p>Deciding which variables are going to be accounted for, how the labels will be defined, and what is considered to be within or outside the scope of the classification problem is <em>difficult</em>. It requires domain knowledge (you must know a few things about birds in order to establish criteria to classify birds), and knowledge of how the classification methods operate (in order to have just the right amount of overlap between features in order to provide meaningful estimates of distance).</p>
</section>
<section id="the-problem-classifying-pixels-from-an-image" class="level2 page-columns page-full" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="the-problem-classifying-pixels-from-an-image"><span class="header-section-number">2.2</span> The problem: classifying pixels from an image</h2>
<p>Throughout this chapter, we will work on a single image – we may initially balk at the idea that an image is data, but it is! Specifically, an image is a series of instances (the pixels), each described by their position in a multidimensional colorimetric space. Greyscale images have one dimension, and images in color will have three: their red, green, and blue channels. Not only are images data, this specific dataset is going to be far larger than many of the datasets we will work on in practice: the number of pixels we work with is given by the product of the width, height, and depth of the image!</p>
<p>In fact, we are going to use an image with many dimensions: the data in this chapter are coming from a Landsat 9 scene <span class="citation" data-cites="vermote2016">(<a href="#ref-vermote2016" role="doc-biblioref">Vermote <em>et al.</em> 2016</a>)</span>, for which we have access to 9 different bands.</p>
<table class="table">
<caption>Overview of the bands in a Landsat 9 scene. The data from this chapter were downloaded from <a href="https://landsatlook.usgs.gov">LandsatLook</a>.</caption>
<thead>
<tr class="header">
<th>Band</th>
<th>Measure</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Aerosol</td>
<td>Good proxy for Chl. in oceans</td>
</tr>
<tr class="even">
<td>2</td>
<td>Visible blue</td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td>Visible green</td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td>Visible red</td>
<td></td>
</tr>
<tr class="odd">
<td>5</td>
<td>Near-infrared (NIR)</td>
<td>Reflected by healthy plants</td>
</tr>
<tr class="even">
<td>6, 7</td>
<td>Short wavelength IR (SWIR 1)</td>
<td>Good at differentiating wet earth and dry earth</td>
</tr>
<tr class="odd">
<td>8</td>
<td>Panchromatic</td>
<td>High-resolution monochrome</td>
</tr>
<tr class="even">
<td>9</td>
<td>Cirrus band</td>
<td>Can pick up high and thin clouds</td>
</tr>
<tr class="odd">
<td>10, 11</td>
<td>Thermal infrared</td>
<td></td>
</tr>
</tbody>
</table>
<p>By using the data present in the channels, we can reconstruct an approximation of what the landscape looked like (by using the red, green, and blue channels).</p>
<p>Or can we?</p>
<p>If we were to invent a time machine, and go stand directly under Landsat 9 at the exact center of this scene, and look around, what would we see? We would see colors, and they would admit a representation as a three-dimensional vector of red, green, and blue. But we would see so much more than that! And even if we were to stand within a pixel, we would see a <em>lot</em> of colors. And texture. And depth. We would see something entirely different from this map; and we would be able to draw a lot more inferences about our surroundings than what is possible by knowing the average color of a 30x30 meters pixel. But just like we can get more information that Landsat 9, so too can Landsat 9 out-sense us when it comes to getting information. In the same way that we can extract a natural color composite out of the different channels, we can extract a fake color one to highlight differences in the landscape.</p>
<div id="cell-fig-kmeans-composites" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="1">
<div id="fig-kmeans-composites" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kmeans-composites-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="clustering_files/figure-html/fig-kmeans-composites-output-1.png" width="1000" height="960" class="figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kmeans-composites-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: The Landsat 9 data are combined into the “Natural Color” image, in which the red, green, and blue bands are mapped to their respective channels (left). The other composites is a 6-5-4 image meant to show differences between urban areas, vegetations, and crops. Note that the true-color composite is slightly distored compared to the colors of the landscape we expect; this is because natural colors are difficult to reproduce accurately.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-kmeans-composites" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, we compare the natural color reconstruction (top) to a false color composite. All of the panels in <a href="#fig-kmeans-composites" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> represent the same physical place at the same moment in time; but through them, we are looking at this place with very different purposes. This is not an idle observation, but a core notion in data science: <em>what we measure defines what we can see</em>. In order to tell something ecologically meaningful about this place, we need to look at it in the “right” way. Of course, although remote sensing offers a promising way to collect data for biodiversity monitoring at scale <span class="citation" data-cites="gonzalez2023">(<a href="#ref-gonzalez2023" role="doc-biblioref">Gonzalez <em>et al.</em> 2023</a>)</span>, there is no guarantee that it will be the right approach for all problems. More (fancier) data is not necessarily right for all problems.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>We will revisit the issue of variable selection and feature engineering in <span class="quarto-unresolved-ref">?sec-variable-selection</span>.</p>
</div></div><p>So far, we have looked at this area by combining the raw data. Depending on the question we have in mind, they may not be the <em>right</em> data. In fact, they may not hold information that is relevant to our question <em>at all</em>; or worse, they can hold more noise than signal. The area we will work on in this chapter is a very small crop of a Landsat 9 scene, taken on path 14 and row 28, early in late June 2023. It shows the western tip of the island of Montréal, as well as Lake Saint-Louis to the south (not actually a lake), Lake Deux-Montages to the north (not actually a lake either), and a small part of Oka national park. This is an interesting area because it has a high variety of environments: large bodies of water, forested areas (bright green in the composite), densely urbanized places (bright purple and white in the composite), less densely urbanized (green-brown), and cropland to the western tip of the island.</p>
<p>But can we classify these different environments starting in an ecologically relevant way? Based on our knowledge of plants, we can start thinking about this question in a different way. Specifically, “can we guess that a pixel contains plants?”, and “can we guess at how much water there is in a pixel?”. Thankfully, ecologists, whose hobbies include (i) guesswork and (ii) plants, have ways to answer these questions rather accurately.</p>
<p>One way to do this is to calculate the normalized difference vegetation index, or NDVI <span class="citation" data-cites="kennedy2020">(<a href="#ref-kennedy2020" role="doc-biblioref">Kennedy &amp; Burbach 2020</a>)</span>. NDVI is derived from the band data (NIR - Red), and there is an adequate heuristic using it to make a difference between vegetation, barren soil, and water. Because plants are immediately tied to water, we can also consider the NDWI (water; Green - NIR) and NDMI (moisture; NIR - SWIR1) dimensions: taken together, these information will represent every pixel in a three-dimensional space, telling us whether there are plants (NDVI), whether they are stressed (NDMI), and whether this pixel is a water body (NDWI). Other commonly used indices based on Landsat 9 data include the NBR (Normalized Burned Ratio), for which high values are suggestive of a history of intense fire <span class="citation" data-cites="roy2006">(<a href="#ref-roy2006" role="doc-biblioref">Roy <em>et al.</em> 2006</a> have challenged the idea that this measure is relevant immediately post-fire)</span>, and the NDBI (Normalized Difference Built-up Index) for urban areas.</p>
<p>We can look at the relationship between the NDVI and NDMI data <a href="#fig-kmeans-hexbin" class="quarto-xref">Figure&nbsp;<span>2.2</span></a>. For example, NDMI values around -0.1 are <a href="https://eos.com/make-an-analysis/ndmi/">low-canopy cover with low water stress</a>; NDVI values from 0.2 to 0.5 are good candidates for moderately dense crops. Notice that there is a strong (linear) relationship between NDVI and NDMI. Indeed, none of these indices are really independent; this implies that they are likely to be more informative taken together than when looking at them one at a time <span class="citation" data-cites="zheng2021">(<a href="#ref-zheng2021" role="doc-biblioref">Zheng <em>et al.</em> 2021</a>)</span>. Indeed, urban area tend to have high values of the NDWI, which makes the specific task of looking for swimming pools (for mosquito control) more challenging than it sounds <span class="citation" data-cites="mcfeeters2013">(<a href="#ref-mcfeeters2013" role="doc-biblioref">McFeeters 2013</a>)</span>.</p>
<div id="cell-fig-kmeans-hexbin" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="1">
<div id="fig-kmeans-hexbin" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kmeans-hexbin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="clustering_files/figure-html/fig-kmeans-hexbin-output-1.png" width="1000" height="600" class="figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kmeans-hexbin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: The pixels acquired from Landsat 9 exist in a space with many different dimensions (one for each band). Because we are interested in a landscape classification based on water and vegetation data, we use the NDVI, NDMI, and NDWI combinations of bands. These are <em>derived</em> data, and represent the creation of new features from the raw data. Darker colors indicate more pixels in this bin.
</figcaption>
</figure>
</div>
</div>
</div>
<p>By picking these four transformed values, instead of simply looking at the clustering of all the bands in the raw data, we are starting to refine what the algorithm sees, through the lens of what we know is important about the system. With these data in hands, we can start building a classification algorithm.</p>
</section>
<section id="the-theory-behind-k-means-clustering" class="level2 page-columns page-full" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="the-theory-behind-k-means-clustering"><span class="header-section-number">2.3</span> The theory behind <em>k</em>-means clustering</h2>
<p>In order to understand the theory underlying <em>k</em>-means, we will work backwards from its output. As a method for clustering, <em>k</em>-means will return a vector of <em>class memberships</em>, which is to say, a list that maps each observation (pixel, in our case) to a class (tentatively, a cohesive landscape unit). What this means is that <em>k</em>-means is a transformation, taking as its input a vector with three dimensions (NDVI, NDMI, NDWI), and returning a scalar (an integer, even!), giving the class to which this pixel belongs. Pixels only belongs to one class. These are the input and output of our blackbox, and now we can start figuring out its internals.</p>
<section id="inputs-and-parameters" class="level3 page-columns page-full" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="inputs-and-parameters"><span class="header-section-number">2.3.1</span> Inputs and parameters</h3>

<div class="no-row-height column-margin column-container"><div class="">
<p>Throughout this book, we will use <span class="math inline">\(\mathbf{X}\)</span> to note the matrix of features, and <span class="math inline">\(\mathbf{y}\)</span> to note the vector of labels. Instances are columns of the features matrix, noted <span class="math inline">\(\mathbf{x}_i\)</span>.</p>
</div></div><p>In <em>k</em>-means, a set of observations <span class="math inline">\(\mathbf{x}_i\)</span> are assigned to a set of classes <span class="math inline">\(\mathbf{C}\)</span>, also called the clusters. All <span class="math inline">\(\mathbf{x}_i\)</span> are vectors with the same dimension (we will call it <span class="math inline">\(f\)</span>, for <em>features</em>), and we can think of our observations as a matrix of features <span class="math inline">\(\mathbf{X}\)</span> of size <span class="math inline">\((f, n)\)</span>, with <span class="math inline">\(f\)</span> features and <span class="math inline">\(n\)</span> observations (the columns of this matrix).</p>
<p>The number of classes of <span class="math inline">\(\mathbf{C}\)</span> is <span class="math inline">\(|\mathbf{C}| = k\)</span>, and <span class="math inline">\(k\)</span> is an hyper-parameter of the model, as it needs to fixed before we start running the algorithm. Each class is defined by its centroid, a vector <span class="math inline">\(\mathbf{c}\)</span> with <span class="math inline">\(f\)</span> dimensions (<em>i.e.</em> the centroid corresponds to a potential “idealized” observation of this class in the space of the features), which <em>k</em>-means progressively refines.</p>
</section>
<section id="assigning-instances-to-classes" class="level3 page-columns page-full" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="assigning-instances-to-classes"><span class="header-section-number">2.3.2</span> Assigning instances to classes</h3>

<div class="no-row-height column-margin column-container"><div class="">
<p>Of course, the correct distance measure to use depends on what is appropriate for the data!</p>
</div></div><p>Instances are assigned to the class for which the distance between themselves and the centroid of this class is lower than the distance between themselves and the centroid of any other class. To phrase it differently, the class membership of an instance <span class="math inline">\(\mathbf{x}_i\)</span> is given by</p>
<p><span id="eq-clustering-onepoint"><span class="math display">\[
\text{argmin}_j \left\|\mathbf{x}_i-\mathbf{c}_j\right\|_2 \,,
\tag{2.1}\]</span></span></p>
<p>which is the value of <span class="math inline">\(j\)</span> that minimizes the <span class="math inline">\(L^2\)</span> norm (<span class="math inline">\(\|\cdot\|_2\)</span>, the Euclidean distance) between the instance and the centroid; <span class="math inline">\(\text{argmin}_j\)</span> is the function returning the value of <span class="math inline">\(j\)</span> that minimizes its argument. For example, <span class="math inline">\(\text{argmin}(0.2,0.8,0.0)\)</span> is <span class="math inline">\(3\)</span>, as the third argument is the smallest. There exists an <span class="math inline">\(\text{argmax}\)</span> function, which works in the same way.</p>
</section>
<section id="optimizing-the-centroids" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="optimizing-the-centroids"><span class="header-section-number">2.3.3</span> Optimizing the centroids</h3>
<p>Of course, what we really care about is the assignment of <em>all</em> instances to the classes. For this reason, the configuration (the disposition of the centroids) that solves our specific problem is the one that leads to the lowest possible variance within the clusters. As it turns out, it is not that difficult to go from <a href="#eq-clustering-onepoint" class="quarto-xref">Equation&nbsp;<span>2.1</span></a> to a solution for the entire problem: we simply have to sum over all points!</p>
<p>This leads to a measure of the variance, which we want to minimize, expressed as</p>
<p><span id="eq-clustering-variance"><span class="math display">\[
\sum_{i=1}^k \sum_{\mathbf{x}\in \mathbf{C}_i} \|\mathbf{x} - \mathbf{c}_i\|_2 \,.
\tag{2.2}\]</span></span></p>
<p>The part that is non-trivial is now to decide on the value of <span class="math inline">\(\mathbf{c}\)</span> for each class. This is the heart of the <em>k</em>-means algorithm. From <a href="#eq-clustering-onepoint" class="quarto-xref">Equation&nbsp;<span>2.1</span></a>, we have a criteria to decide to which class each instance belongs. Of course, there is nothing that prevents us from using this in the opposite direction, to define the instance by the points that form it! In this approach, the membership of class <span class="math inline">\(\mathbf{C}_j\)</span> is the list of points that satisfy the condition in <a href="#eq-clustering-onepoint" class="quarto-xref">Equation&nbsp;<span>2.1</span></a>. But there is no guarantee that the <em>current</em> position of <span class="math inline">\(\mathbf{c}_j\)</span> in the middle of all of these points is optimal, <em>i.e.</em> that it minimizes the within-class variance.</p>
<p>This is easily achieved, however. To ensure that this is the case, we can re-define the value of <span class="math inline">\(\mathbf{c}_j\)</span> as</p>
<p><span id="eq-clustering-centroid-update"><span class="math display">\[
\mathbf{c}_j = \frac{1}{|\mathbf{C}_j|}\sum\mathbf{C}_j \,,
\tag{2.3}\]</span></span></p>
<p>where <span class="math inline">\(|\cdot|\)</span> is the cardinality of (number of istances in) <span class="math inline">\(\mathbf{C}_j\)</span>, and <span class="math inline">\(\sum \mathbf{C}_j\)</span> is the sum of each feature in <span class="math inline">\(\mathbf{C}_j\)</span>. To put it plainly: we update the centroid of <span class="math inline">\(\mathbf{C}_j\)</span> so that it takes, for each feature, the average value of all the instances that form <span class="math inline">\(\mathbf{C}_j\)</span>.</p>
</section>
<section id="updating-the-classes" class="level3 page-columns page-full" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="updating-the-classes"><span class="header-section-number">2.3.4</span> Updating the classes</h3>

<div class="no-row-height column-margin column-container"><div class="">
<p>Repeating a step multiple times in a row is called an iterative process, and we will see a <em>lot</em> of them.</p>
</div></div><p>Once we have applied <a href="#eq-clustering-centroid-update" class="quarto-xref">Equation&nbsp;<span>2.3</span></a> to all classes, there is a good chance that we have moved the centroids in a way that moved them away from some of the points, and closer to others: the membership of the instances has likely changed. Therefore, we need to re-start the process again, in an iterative way.</p>
<p>But until when?</p>
<p>Finding the optimal solution for a set of points is an NP-hard problem <span class="citation" data-cites="aloise2009">(<a href="#ref-aloise2009" role="doc-biblioref">Aloise <em>et al.</em> 2009</a>)</span>, which means that we will need to rely on a little bit of luck, or a whole lot of time. The simplest way to deal with iterative processes is to let them run for a long time, as after a little while they should converge onto an optimum (here, a set of centroids for which the variance is as good as it gets), and hope that this optimum is <em>global</em> and not <em>local</em>.</p>
<p>A global optimum is easy to define: it is the state of the solution that gives the best possible result. For this specific problem, a global optimum means that there are no other combinations of centroids that give a lower variance. A local optimum is a little bit more subtle: it means that we have found a combination of centroids that we cannot improve without first making the variance worse. Because the algorithm as we have introduced it in the previous sections is <em>greedy</em>, in that it makes the moves that give the best short-term improvement, it will not provide a solution that temporarily makes the variance higher, and therefore is susceptible to being trapped in a local optimum.</p>
<p>In order to get the best possible solution, it is therefore common to run <em>k</em>-means multiple times for a given <span class="math inline">\(k\)</span>, and to pick the positions of the centroids that give the best overall fit.</p>
</section>
<section id="sec-clustering-optimality" class="level3 page-columns page-full" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="sec-clustering-optimality"><span class="header-section-number">2.3.5</span> Identification of the optimal number of clusters</h3>
<p>One question that is left un-answered is the value of <span class="math inline">\(k\)</span>. How do we decide on the number of clusters?</p>
<p>There are two solutions here. One is to have an <em>a priori</em> knowledge of the number of classes. For example, if the purpose of clustering is to create groups for some specific task, there might be an upper/lower bound to the number of tasks you are willing to consider. The other solution is to run the algorithm in a way that optimizes the number of clusters for us.</p>
<p>This second solution turns out to be rather simple with <em>k</em>-means. We need to change the value of <span class="math inline">\(k\)</span>, run it on the same dataset several times, and then pick the solution that was <em>optimal</em>. But this is not trivial. Simply using <a href="#eq-clustering-variance" class="quarto-xref">Equation&nbsp;<span>2.2</span></a> would lead to always preferring many clusters. After all, each point in its own cluster would get a pretty low variance!</p>
<p>For this reason, we use measures of optimality that are a little more refined. One of them is the <span class="citation" data-cites="davies1979">Davies &amp; Bouldin (<a href="#ref-davies1979" role="doc-biblioref">1979</a>)</span> method, which is built around a simple idea: an assignment of instances to clusters is good if the instances within a cluster are not too far away from the centroids, and the centroids are as far away from one another as possible.</p>
<p>The Davies-Bouldin measure is striking in its simplicity. From a series of points and their assigned clusters, we only need to compute two things. The first is a vector <span class="math inline">\(\mathbf{s}\)</span>, which holds the average distance between the points and their centroids (this is the <span class="math inline">\(\left\|\mathbf{x}_i-\mathbf{c}_j\right\|_2\)</span> term in <a href="#eq-clustering-onepoint" class="quarto-xref">Equation&nbsp;<span>2.1</span></a>, so this measure still relates directly to the variance); the second is a matrix <span class="math inline">\(\mathbf{M}\)</span>, which measures the distances <em>between</em> the centroids.</p>
<p>These two information are combined in a matrix <span class="math inline">\(\mathbf{R}\)</span>, wherein <span class="math inline">\(\mathbf{R}_{ij} = (s_i + s_j)/\mathbf{M}_{ij}\)</span>. The interpretation of this term is quite simply: is the average distance <em>within</em> clusters <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> much larger compared to the distance <em>between</em> these clusters. This is, in a sense, a measure of the stress that these two clusters impose on the entire system. In order to turn this matrix into a single value, we calculate the maximum value (ignoring the diagonal!) for each row: this is a measure of the <em>maximal</em> amount of stress in which a cluster is involved. By averaging these values across all clusters, we have a measure of the quality of the assignment, that can be compared for multiple values of <span class="math inline">\(k\)</span>.</p>
<p>Note that this approach protects us against the each-point-in-its-cluster situation: in this scenario, the distance between clusters would decrease really rapidly, meaning that the values in <span class="math inline">\(\mathbf{R}\)</span> would <em>increase</em>; the Davies-Bouldin measure indicates a better clustering when the values are <em>lower</em>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In fact, there is very little enumeration of techniques in this book. The important point is to understand how all of the pieces fit together, not to make a census of all possible pieces.</p>
</div></div><p>There are alternatives to this method, including silhouettes <span class="citation" data-cites="rousseeuw1987">(<a href="#ref-rousseeuw1987" role="doc-biblioref">Rousseeuw 1987</a>)</span> and the technique of <span class="citation" data-cites="dunn1974">Dunn (<a href="#ref-dunn1974" role="doc-biblioref">1974</a>)</span>. The question of optimizing the number of clusters goes back several decades <span class="citation" data-cites="thorndike1953">(<a href="#ref-thorndike1953" role="doc-biblioref">Thorndike 1953</a>)</span>, and it still actively studied. What matter is less to give a comprehensive overview of all the measures: the message here is to pick one that works (and can be justified) for your specific problem!</p>
</section>
</section>
<section id="application-optimal-clustering-of-the-satellite-image-data" class="level2 page-columns page-full" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="application-optimal-clustering-of-the-satellite-image-data"><span class="header-section-number">2.4</span> Application: optimal clustering of the satellite image data</h2>
<section id="sec-kmeans-initial" class="level3 page-columns page-full" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="sec-kmeans-initial"><span class="header-section-number">2.4.1</span> Initial run</h3>
<p>Before we do anything else, we need to run our algorithm with a random pick of hyper-parameters, in order to get a sense of how hard the task ahead is. In this case, using <span class="math inline">\(k = 3\)</span>, we get the results presented in <a href="#fig-kmeans-initial-landscape" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>.</p>
<div id="cell-fig-kmeans-initial-landscape" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="1">
<div id="fig-kmeans-initial-landscape" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kmeans-initial-landscape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="clustering_files/figure-html/fig-kmeans-initial-landscape-output-1.png" width="1000" height="480" class="figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kmeans-initial-landscape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: caption
</figcaption>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>After iterating the <em>k</em>-means algorithm, we obtain a classification for every pixel in the landscape. This classification is based on the values of NDVI, NDMI, and NDWI indices, and therefore groups pixels based on specific assumptions about vegetation and stress. This clustering was produced using <span class="math inline">\(k=3\)</span>, <em>i.e.</em> we want to see what the landscape would look like when divided into three categories.</p>
</blockquote>

<div class="no-row-height column-margin column-container"><div class="">
<p>In fact, take some time to think about how you would use <span class="math inline">\(k\)</span>-means to come up with a way to remove pixels with only water from this image!</p>
</div></div><p>It is always a good idea to look at the first results and state the obvious. Here, for example, we can say that water is easy to identify. In fact, removing open water pixels from images is an interesting image analysis challenge <span class="citation" data-cites="mondejar2019">(<a href="#ref-mondejar2019" role="doc-biblioref">Mondejar &amp; Tongco 2019</a>)</span>, and because we used an index that specifically identifies water bodies (NDWI), it is not surprising that there is an entire cluster that seems to be associated with water. But if we take a better look, it appears that there groups of pixels that represent dense urban areas that are classified with the water pixels. When looking at the landscape in a space with three dimensions, it looks like separating densely built-up environment and water is difficult.</p>
<p>This might seem like an idle observation, but this is not the case! It means that when working on vegetation-related questions, we will likely need at least one cluster for water, and one cluster for built-up areas. This is helpful information, because we can already think about how many classes of vegetation we are willing to accept, and add (at least) two clusters to capture other types of cover.</p>
</section>
<section id="optimal-number-of-pixels" class="level3 page-columns page-full" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="optimal-number-of-pixels"><span class="header-section-number">2.4.2</span> Optimal number of pixels</h3>

<div class="no-row-height column-margin column-container"><div class="">
<p>We will revisit the issue of tuning the hyper-parameters in more depth in <span class="quarto-unresolved-ref">?sec-tuning</span>.</p>
</div></div><p>In order to produce <a href="#fig-kmeans-initial-landscape" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>, we had to guess at a number of classes we wanted to split the landscape into. This introduces two important steps in coming up with a model: starting with initial parameters in order to iterate rapidly, and then refining these parameters to deliver a model that is fit for purpose. Our discussion in <a href="#sec-kmeans-initial" class="quarto-xref"><span>Section 2.4.1</span></a>, where we concluded that we needed to keep (maybe) two classes for water and built-up is not really satisfying, as we do not yet have a benchmark to evaluate the correct value of <span class="math inline">\(k\)</span>; we know that it is more than 3, but how much more?</p>
<p>We will now change the values of <span class="math inline">\(k\)</span> and use the <span class="citation" data-cites="davies1979">Davies &amp; Bouldin (<a href="#ref-davies1979" role="doc-biblioref">1979</a>)</span> measure introduced in <a href="#sec-clustering-optimality" class="quarto-xref"><span>Section 2.3.5</span></a> to identify the optimal value of <span class="math inline">\(k\)</span>. The results are presented in <a href="#fig-kmeans-tuning" class="quarto-xref">Figure&nbsp;<span>2.4</span></a>. Note that we only explore <span class="math inline">\(k \in [3, 10]\)</span>. More than 8 categories is probably not very actionable, and therefore we can make the decision to only look at this range of parameters. Sometimes (always!) the best solution is the one that gets your job done.</p>
<div id="cell-fig-kmeans-tuning" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="1">
<div id="fig-kmeans-tuning" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kmeans-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="clustering_files/figure-html/fig-kmeans-tuning-output-1.png" width="1000" height="1000" class="figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kmeans-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Results of running the <em>k</em>-means algorithm ten times for each number of clusters between 3 and 8. The average Davies-Bouldin and cost are reported, as well as the standard deviation. As expected, the total cost decreases with more clusters, but this is not necessarily the sign of a better clustering.
</figcaption>
</figure>
</div>
</div>
</div>
<p>There are two interesting things in <a href="#fig-kmeans-tuning" class="quarto-xref">Figure&nbsp;<span>2.4</span></a>. First, note that for <span class="math inline">\(k=\{3,4\}\)</span>, there is almost no dispersal: all of the assignments have the exact same score, which is unlikely to happen except if the assignments are the same every time! This is a good sign, and, anecdotally, something that might suggest a really information separation of the points. Second, <span class="math inline">\(k = 3\)</span> has by far the lowest Davies-Bouldin index of all values we tried, and is therefore strongly suggestive of an optimal hyper-parameter. But in <a href="#fig-kmeans-initial-landscape" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>, we already established that one of these clusters was capturing <em>both</em> water and built-up environments, so although it may look better from a quantitative point of view, it is not an ideal solution <em>for the specific problem we have</em>.</p>
<p>In this specific case, it makers very little sense <em>not</em> to use <span class="math inline">\(k = 4\)</span> or <span class="math inline">\(k = 5\)</span>. They have about the same performance, but this gives us potentially more classes that are neither water nor built-up. This image is one of many cases where it is acceptable to sacrifice a little bit of optimality in order to present more actionable information. Based on the results in this section, we will pick the largest possible <span class="math inline">\(k\)</span> that does not lead to a drop in performance, which in our case is <span class="math inline">\(k=5\)</span>.</p>
</section>
<section id="clustering-with-optimal-number-of-classes" class="level3 page-columns page-full" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="clustering-with-optimal-number-of-classes"><span class="header-section-number">2.4.3</span> Clustering with optimal number of classes</h3>
<p>The clustering of pixels using <span class="math inline">\(k = 5\)</span> is presented in <a href="#fig-kmeans-optimal-landscape" class="quarto-xref">Figure&nbsp;<span>2.5</span></a>. Unsurprisingly, <em>k</em>-means separated the open water pixels, the dense urban areas, as well as the more forested/green areas. Now is a good idea to start thinking about what is representative of these clusters: one is associated with very high NDWI value (these are the water pixels), and two classes have both high NDVI and high NDMI (suggesting different categories of vegetation).</p>
<div id="cell-fig-kmeans-optimal-landscape" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-stdout">
<pre><code>┌ Warning: The clustering cost increased at iteration #16
└ @ Clustering ~/.julia/packages/Clustering/JwhfU/src/kmeans.jl:191
┌ Warning: The clustering cost increased at iteration #18
└ @ Clustering ~/.julia/packages/Clustering/JwhfU/src/kmeans.jl:191
┌ Warning: The clustering cost increased at iteration #21
└ @ Clustering ~/.julia/packages/Clustering/JwhfU/src/kmeans.jl:191
┌ Warning: The clustering cost increased at iteration #24
└ @ Clustering ~/.julia/packages/Clustering/JwhfU/src/kmeans.jl:191
┌ Warning: The clustering cost increased at iteration #27
└ @ Clustering ~/.julia/packages/Clustering/JwhfU/src/kmeans.jl:191</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="1">
<div id="fig-kmeans-optimal-landscape" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kmeans-optimal-landscape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="clustering_files/figure-html/fig-kmeans-optimal-landscape-output-2.png" width="1000" height="480" class="figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kmeans-optimal-landscape-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: Results of the landscape clustering with k=5 clusters. This number of clusters gives us a good separation between different groups of pixels, and seems to capture features of the landscape as revealed with the false-color composites.
</figcaption>
</figure>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>We will revisit the issue of understanding how a model makes a prediction in <span class="quarto-unresolved-ref">?sec-explanations</span>.</p>
</div></div><p>The relative size of the clusters (as well as the position of their centroids) is presented in <a href="#tbl-clustering-centers" class="quarto-xref">Table&nbsp;<span>2.1</span></a>. There is a good difference in the size of the clusters, which is an important thing to note. Indeed, a common myth about <em>k</em>-means is that it gives clusters of the same size. This “size” does not refer to the cardinality of the clusters, but to the volume that they cover in the space of the parameters. If an area of the space of parameters is more densely packed with instances, the cluster covering the area will have more points!</p>
<div id="tbl-clustering-centers" class="cell quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-execution_count="1">
<figure class="quarto-float quarto-float-tbl figure page-columns page-full">
<div aria-describedby="tbl-clustering-centers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="cell table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;"><strong>Cluster</strong></th>
<th style="text-align: right;"><strong>Cover</strong></th>
<th style="text-align: right;"><strong>NDVI</strong></th>
<th style="text-align: right;"><strong>NDWI</strong></th>
<th style="text-align: right;"><strong>NDMI</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">38</td>
<td style="text-align: right;">-0.018</td>
<td style="text-align: right;">0.012</td>
<td style="text-align: right;">0.006</td>
</tr>
<tr class="even">
<td style="text-align: right;">5</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">0.096</td>
<td style="text-align: right;">-0.152</td>
<td style="text-align: right;">0.005</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">0.224</td>
<td style="text-align: right;">-0.262</td>
<td style="text-align: right;">0.08</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0.32</td>
<td style="text-align: right;">-0.343</td>
<td style="text-align: right;">0.139</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">0.439</td>
<td style="text-align: right;">-0.443</td>
<td style="text-align: right;">0.223</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-tbl margin-caption" id="tbl-clustering-centers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.1: Summary of the values for the centers of the optimal clusters found in this image. The cover column gives the percentage of all pixels associated to this class. The clusters are sorted by the NDVI of their centroid.
</figcaption>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>In fact, this behavior makes <em>k</em>-means excellent at creating color palettes from images! Cases in point, <a href="https://github.com/karthik/wesanderson">Karthik Ram’s Wes Anderson palettes</a>, and <a href="https://github.com/dill/beyonce">David Lawrence Miller’s Beyoncé palettes</a>. Let it never again be said that ecologists should not be trusted with machine learning methods.</p>
</div></div><p>The area of the space of parameters covered by each cluster in represented in <a href="#fig-kmeans-clustering" class="quarto-xref">Figure&nbsp;<span>2.6</span></a>, and this result is actually not surprising, if we spend some time thinking about how <em>k</em>-means work. Because our criteria to assign a point to a cluster is based on the being closest to its centroid than to any other centroid, we are essentially creating Voronoi cells, with linear boundaries between them.</p>
<p>By opposition to a model based on, for example, mixtures of Gaussians, the assignment of a point to a cluster in <em>k</em>-means is independent of the current composition of the cluster (modulo the fact that the current composition of the cluster is used to update the centroids). In fact, this makes <em>k</em>-means closer to (or at least most efficient as) a method for quantization <span class="citation" data-cites="gray1984">(<a href="#ref-gray1984" role="doc-biblioref">Gray 1984</a>)</span>.</p>
<div id="cell-fig-kmeans-clustering" class="cell page-columns page-full" data-execution_count="1">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="1">
<div id="fig-kmeans-clustering" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-kmeans-clustering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="clustering_files/figure-html/fig-kmeans-clustering-output-1.png" width="1000" height="600" class="figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-kmeans-clustering-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: Visualisation of the clustering output as a function of the NDVI and NDMI values. Note that the limits between the clusters are lines (planes), and that each cluster covers about the same volume in the space of parameters.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">2.5</span> Conclusion</h2>
<p>In this chapter, we have used the <em>k</em>-means algorithm to create groups in a large dataset that had no labels, <em>i.e.</em> the points were not assigned to a class. By picking the features we wanted to cluster the point, we were able to highlight specific aspects of the landscape. In <span class="quarto-unresolved-ref">?sec-gradientdescent</span>, we will start adding labels to our data, and shift our attention from classification to regression problems.</p>


<div id="3ade8a4a-fb1d-4a6c-8409-ac45482d5fc9" class="hidden">

</div>
</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aloise2009" class="csl-entry" role="listitem">
Aloise, D., Deshpande, A., Hansen, P. &amp; Popat, P. (2009). <a href="https://doi.org/10.1007/s10994-009-5103-0">NP-hardness of Euclidean sum-of-squares clustering</a>. <em>Machine Learning</em>, 75, 245–248.
</div>
<div id="ref-cooney2022" class="csl-entry" role="listitem">
Cooney, C.R., He, Y., Varley, Z.K., Nouri, L.O., Moody, C.J.A., Jardine, M.D., <em>et al.</em> (2022). <a href="https://doi.org/10.1038/s41559-022-01714-1">Latitudinal gradients in avian colourfulness</a>. <em>Nature Ecology &amp; Evolution</em>, 6, 622–629.
</div>
<div id="ref-cooper2019" class="csl-entry" role="listitem">
Cooper, N., Bond, A.L., Davis, J.L., Portela Miguez, R., Tomsett, L. &amp; Helgen, K.M. (2019). <a href="https://doi.org/10.1098/rspb.2019.2025">Sex biases in bird and mammal natural history collections</a>. <em>Proceedings of the Royal Society B: Biological Sciences</em>, 286, 20192025.
</div>
<div id="ref-davies1979" class="csl-entry" role="listitem">
Davies, D.L. &amp; Bouldin, D.W. (1979). <a href="https://doi.org/10.1109/tpami.1979.4766909">A cluster separation measure</a>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, PAMI-1, 224–227.
</div>
<div id="ref-dunn1974" class="csl-entry" role="listitem">
Dunn, J.C. (1974). <a href="https://doi.org/10.1080/01969727408546059">Well-Separated Clusters and Optimal Fuzzy Partitions</a>. <em>Journal of Cybernetics</em>, 4, 95–104.
</div>
<div id="ref-gonzalez2023" class="csl-entry" role="listitem">
Gonzalez, A., Vihervaara, P., Balvanera, P., Bates, A.E., Bayraktarov, E., Bellingham, P.J., <em>et al.</em> (2023). <a href="https://doi.org/10.1038/s41559-023-02171-0">A global biodiversity observing system to unite monitoring and guide action</a>. <em>Nature Ecology &amp; Evolution</em>.
</div>
<div id="ref-gray1984" class="csl-entry" role="listitem">
Gray, R. (1984). <a href="https://doi.org/10.1109/massp.1984.1162229">Vector quantization</a>. <em>IEEE ASSP Magazine</em>, 1, 4–29.
</div>
<div id="ref-kennedy2020" class="csl-entry" role="listitem">
Kennedy, S. &amp; Burbach, M. (2020). <a href="https://doi.org/10.1353/gpr.2020.0016">Great Plains Ranchers Managing for Vegetation Heterogeneity: A Multiple Case Study</a>. <em>Great Plains Research</em>, 30, 137–148.
</div>
<div id="ref-luccioni2023" class="csl-entry" role="listitem">
Luccioni, A.S. &amp; Rolnick, D. (2023). <a href="https://doi.org/10.1609/aaai.v37i12.26682">Bugs in the data: How ImageNet misrepresents biodiversity</a>. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 37, 14382–14390.
</div>
<div id="ref-mcfeeters2013" class="csl-entry" role="listitem">
McFeeters, S. (2013). <a href="https://doi.org/10.3390/rs5073544">Using the Normalized Difference Water Index (NDWI) within a Geographic Information System to Detect Swimming Pools for Mosquito Abatement: A Practical Approach</a>. <em>Remote Sensing</em>, 5, 3544–3561.
</div>
<div id="ref-mondejar2019" class="csl-entry" role="listitem">
Mondejar, J.P. &amp; Tongco, A.F. (2019). <a href="https://doi.org/10.1186/s42834-019-0016-5">Near infrared band of Landsat 8 as water index: a case study around Cordova and Lapu-Lapu City, Cebu, Philippines</a>. <em>Sustainable Environment Research</em>, 29.
</div>
<div id="ref-rousseeuw1987" class="csl-entry" role="listitem">
Rousseeuw, P.J. (1987). <a href="https://doi.org/10.1016/0377-0427(87)90125-7">Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</a>. <em>Journal of Computational and Applied Mathematics</em>, 20, 53–65.
</div>
<div id="ref-roy2006" class="csl-entry" role="listitem">
Roy, D.P., Boschetti, L. &amp; Trigg, S.N. (2006). <a href="https://doi.org/10.1109/lgrs.2005.858485">Remote Sensing of Fire Severity: Assessing the Performance of the Normalized Burn Ratio</a>. <em>IEEE Geoscience and Remote Sensing Letters</em>, 3, 112–116.
</div>
<div id="ref-thorndike1953" class="csl-entry" role="listitem">
Thorndike, R.L. (1953). <a href="https://doi.org/10.1007/bf02289263">Who belongs in the family?</a> <em>Psychometrika</em>, 18, 267–276.
</div>
<div id="ref-vermote2016" class="csl-entry" role="listitem">
Vermote, E., Justice, C., Claverie, M. &amp; Franch, B. (2016). <a href="https://doi.org/10.1016/j.rse.2016.04.008">Preliminary analysis of the performance of the Landsat 8/OLI land surface reflectance product</a>. <em>Remote Sensing of Environment</em>, 185, 46–56.
</div>
<div id="ref-zheng2021" class="csl-entry" role="listitem">
Zheng, Y., Zhou, Q., He, Y., Wang, C., Wang, X. &amp; Wang, H. (2021). <a href="https://doi.org/10.3390/rs13040766">An Optimized Approach for Extracting Urban Land Based on Log-Transformed DMSP-OLS Nighttime Light, NDVI, and NDWI</a>. <em>Remote Sensing</em>, 13, 766.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work is licensed under the <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International License</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/tpoisot/MLBS/blob/main/chapters/clustering.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/tpoisot/MLBS/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>