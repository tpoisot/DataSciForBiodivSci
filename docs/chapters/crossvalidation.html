<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.386">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Machine Learning for Biodiversity Scientists - 4&nbsp; Cross-validation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": true,
  "collapse-after": 1,
  "panel-placement": "start",
  "type": "overlay",
  "limit": 10,
  "keyboard-shortcut": [
    null
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/crossvalidation.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Cross-validation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning for Biodiversity Scientists</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/tpoisot/MLBS" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../Machine-Learning-for-Biodiversity-Scientists.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div id="quarto-search" class="quarto-navigation-tool px-1" title="Search"></div>
</div>
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/gradientdescent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Gradient descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/crossvalidation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Cross-validation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/variableselection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Selecting variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/learningcurves.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tuning hyper-parameters</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Explaining predictions</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/instructornotes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Instructor notes</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="-1">
    <h2 id="toc-title">Chapter overview</h2>
   
  <ul>
  <li><a href="#how-can-we-split-a-dataset" id="toc-how-can-we-split-a-dataset" class="nav-link active" data-scroll-target="#how-can-we-split-a-dataset"><span class="header-section-number">4.1</span> How can we split a dataset?</a>
  <ul class="collapse">
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training"><span class="header-section-number">4.1.1</span> Training</a></li>
  <li><a href="#validating" id="toc-validating" class="nav-link" data-scroll-target="#validating"><span class="header-section-number">4.1.2</span> Validating</a></li>
  <li><a href="#testing" id="toc-testing" class="nav-link" data-scroll-target="#testing"><span class="header-section-number">4.1.3</span> Testing</a></li>
  </ul></li>
  <li><a href="#the-problem-cherry-blossom-phenology" id="toc-the-problem-cherry-blossom-phenology" class="nav-link" data-scroll-target="#the-problem-cherry-blossom-phenology"><span class="header-section-number">4.2</span> The problem: cherry blossom phenology</a></li>
  <li><a href="#strategies-to-split-data" id="toc-strategies-to-split-data" class="nav-link" data-scroll-target="#strategies-to-split-data"><span class="header-section-number">4.3</span> Strategies to split data</a>
  <ul class="collapse">
  <li><a href="#holdout" id="toc-holdout" class="nav-link" data-scroll-target="#holdout"><span class="header-section-number">4.3.1</span> Holdout</a></li>
  <li><a href="#leave-p-out" id="toc-leave-p-out" class="nav-link" data-scroll-target="#leave-p-out"><span class="header-section-number">4.3.2</span> Leave-p-out</a></li>
  <li><a href="#leave-one-out" id="toc-leave-one-out" class="nav-link" data-scroll-target="#leave-one-out"><span class="header-section-number">4.3.3</span> Leave-one-out</a></li>
  <li><a href="#k-fold" id="toc-k-fold" class="nav-link" data-scroll-target="#k-fold"><span class="header-section-number">4.3.4</span> k-fold</a></li>
  <li><a href="#sec-crossvalidation-montecarlo" id="toc-sec-crossvalidation-montecarlo" class="nav-link" data-scroll-target="#sec-crossvalidation-montecarlo"><span class="header-section-number">4.3.5</span> Monte-Carlo</a></li>
  </ul></li>
  <li><a href="#application-when-do-cherry-blossom-bloom" id="toc-application-when-do-cherry-blossom-bloom" class="nav-link" data-scroll-target="#application-when-do-cherry-blossom-bloom"><span class="header-section-number">4.4</span> Application: when do cherry blossom bloom?</a>
  <ul class="collapse">
  <li><a href="#performance-evaluation" id="toc-performance-evaluation" class="nav-link" data-scroll-target="#performance-evaluation"><span class="header-section-number">4.4.1</span> Performance evaluation</a></li>
  <li><a href="#model-predictions" id="toc-model-predictions" class="nav-link" data-scroll-target="#model-predictions"><span class="header-section-number">4.4.2</span> Model predictions</a></li>
  <li><a href="#sec-crossvalidation-fitness" id="toc-sec-crossvalidation-fitness" class="nav-link" data-scroll-target="#sec-crossvalidation-fitness"><span class="header-section-number">4.4.3</span> Is our model good, then?</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">4.5</span> Conclusion</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/tpoisot/MLBS/blob/main/chapters/crossvalidation.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/tpoisot/MLBS/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-crossvalidation" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Cross-validation</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In <a href="clustering.html" class="quarto-xref"><span>Chapter&nbsp;2</span></a>, we were very lucky. Because we applied an unsupervised method, we didn’t really have a target to compare to the output. Whatever classification we got, we had to live with it. It was incredibly freeing. Sadly, in most applications, we will have to compare our predictions to data, and data are incredibly vexatious. In this chapter, we will develop intuitions on the notions of training, testing, and validation.</p>
<p>In a sense, we started thinking about these concepts in <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>; specifically, we came up with a way to optimize the parameters of our model (<em>i.e.</em> of <em>training</em> our model) based on a series of empirical observations, and a criteria for what a “good fit” is. We further appraised the performance of our model by measuring the loss (our measure of how good the fit is) on a dataset that was not accessible during training, which we called the <em>testing</em> dataset. One issue with our approach in <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a> was that we had to set aside one out of five observation for testing; in this chapter, we will explore more advanced techniques to perform cross-validation.</p>
<section id="how-can-we-split-a-dataset" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="how-can-we-split-a-dataset"><span class="header-section-number">4.1</span> How can we split a dataset?</h2>
<p>There is a much more important question to ask first: <em>why</em> do we split a dataset? In a sense, answering this question echoes the discussion we started in <a href="gradientdescent.html#sec-gradientdescent-overfitting" class="quarto-xref"><span>Section&nbsp;3.4.4</span></a>, because the purpose of splitting a dataset is to ensure we can train and evaluate it properly, in order to deliver the best possible model.</p>
<p>When a model is trained, it has learned from the data, we have tuned its hyper-parameters to ensure that it learned with the best possible conditions, and we have applied a measure of performance <em>after</em> the entire process is complete, to communicate how well we expect our model to work. These three tasks require three different datasets, and this is the purpose of splitting our data into groups.</p>
<p>One of the issues when reading about splitting data is that the terminology can be muddy. For example, what constitutes a testing and validation set can largely be a matter of perspective. In many instances, testing and validation are used interchangeably, especially when there is a single model involved. Nevertheless, it helps to settle on a few guidelines here, before going into the details of what each dataset constitutes and how to assemble it.</p>
<p>The <em>training</em> instances are examples that are given to the model during the training process. This dataset has the least ambiguous definition. The training data is defined by subtraction, in a sense, as whatever is left of the original data after we set aside testing and validation sets.</p>
<p>The <em>testing</em> instances are used at the end of the process, to measure the performance of a trained model with tuned hyper-parameters. If the training data are the lectures, testing data are the final exam: we can measure the performance of the model on this dataset and report it as the model performance we can expect when applying the model to new data. There is a very important, chapter-long, caveat about this last point, related to the potential of information leak between datasets, which is covered in <a href="variableselection.html#sec-leakage" class="quarto-xref"><span>Section&nbsp;6.2</span></a>.</p>
<p>The <em>validation</em> data are used in-between, as part of the training process. They are (possibly) a subset of the training data that we use internally to check the performance of the model, often in order to tune its hyper-parameters, or as a way to report on the over-fitting of the model during the training process.</p>
<p>The difference between testing and validation is largely a difference of <em>intent</em>. When we want to provide an <em>a posteriori</em> assessment of the model performance, the dataset we use to determine this performance is a testing dataset. When we want to optimize some aspect of the model, the data we use for this are the validation data. With this high-level perspective in mind, let’s look at each of these datasets in turn. The differences between these three datasets are summarized in <a href="#tbl-splits-models" class="quarto-xref">Table&nbsp;<span>4.1</span></a>.</p>
<div id="tbl-splits-models" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-splits-models-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 37%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Dataset</th>
<th>Trains</th>
<th>Purpose</th>
<th>Data used for training</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training</td>
<td>yes</td>
<td>train model</td>
<td></td>
</tr>
<tr class="even">
<td>Validation</td>
<td></td>
<td>validate during training</td>
<td>training data only</td>
</tr>
<tr class="odd">
<td>Testing</td>
<td></td>
<td>estimates of future performance</td>
<td>all except testing</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="table quarto-float-caption quarto-float-tbl" id="tbl-splits-models-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4.1: Overview of the three datasets used for training and cross-validation. Information in the “Data used for training” column refer to the data that have been used to train the model when calculating its performance.
</figcaption>
</figure>
</div>
<section id="training" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="training"><span class="header-section-number">4.1.1</span> Training</h3>
<p>In data science (in applied machine learning in particular), we do not <em>fit</em> models. We <em>train</em> them. This is an important difference: training is an iterative process, that we can repeat, optimize, and tweak. The outcome of training and the outcome of fitting are essentially the same (a model that is parameterized to work as well as possible on a given dataset), but it is good practice to adopt the language of a field, and the language of data science emphasizes the different practices in model training.</p>
<p>Training, to provide a general definition, is the action of modifying the parameters of a model, based on knowledge of the data, and the error that results from using the current parameter values. In <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>, for example, we saw how to train a linear model using the technique of gradient descent, based on a specific dataset, with a learning rate and loss function we picked based on trial and error. Our focus in this chapter is not on the methods we use for training, but on the data that are required to train a model.</p>
<p>Training a model is a process akin to rote learning: we will present the same input, and the same expected responses, many times over, and we will find ways for the error on each response to decrease (this is usually achieved by minimizing the loss function).</p>
<p>In order to initiate this process, we need an untrained model. Untrained, in this context, refers to a model that has not been trained <em>on the specific problem</em> we are addressing; the model may have been trained on a different problem (for example, we want to predict the distribution of a species based on a GLM trained on a phylogenetically related species). It is important to note that by “training the model”, what we really mean is “change the structure of the parameters until the output looks right”. For example, assuming a simple linear model like <span class="math inline">\(c(X) = \beta_0 + \beta_1X_1 + \beta_2X_2\)</span>, training this model would lead to changes in the values of <span class="math inline">\(\beta\)</span>, but not to the consideration of a new model <span class="math inline">\(c(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_1X_2\)</span>. Comparing models is (often) the point of validation, which we will address later on.</p>
</section>
<section id="validating" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="validating"><span class="header-section-number">4.1.2</span> Validating</h3>
<p>The easiest way to think about the validation dataset is by thinking about what it is <em>not</em> used for: training the model (this is the training set), and giving a final overview of the model expected performance (this is the testing set). The validation set is used for everything else (model selection, cross-validation, hyper-parameters tuning), albeit in a specific way. With the training set, we communicate the predictors and the labels to the model, and update the weights of the model in response. With the validation set, we communicate the predictors and the labels to the model, but we do <em>not</em> update the weights in response. All we care about during validation is the performance of the model on a problem it has not yet encountered during this specific round of training. If the training set is like attending a lecture, the validation set is formative feedback.</p>
<p>Of course, one issue with the creation of a validation set is that it needs to resemble the problem the model will have to solve in practice. We will discuss this more in depth in the following sections, but it is worth thinking about an example. Assume a model that classifies a picture as having either a black bear, or no black bear. Now, we can train this model using, for example, images from 10 camera traps that are situated in a forest. And we might want to validate with a camera trap that is in a zoo. In one of the enclosures. The one with a bear. A polar one.</p>
<p>The issue with this dataset as a validation dataset is that is does not matches the problem we try to solve in many different ways. First, we will have an excess of images with bears compared to our problem environment. Camera traps can have a large number of spurious activation, resulting in images without animals in them <span class="citation" data-cites="newey2015">(<a href="#ref-newey2015" role="doc-biblioref">Newey et al. 2015</a>)</span>. Second, the data will come from very different environments (forest v. zoo). Finally, we are attempting to validate on something that is an entirely different species of bear. This sounds like an egregious case (it is), but it is easy to commit this type of mistake when our data get more complex than black bear, polar bear, no bear.</p>
<p>Validation is, in particular, very difficult when the dataset we use for training has extreme events <span class="citation" data-cites="bellocchi2010">(<a href="#ref-bellocchi2010" role="doc-biblioref">Bellocchi et al. 2010</a>)</span>. Similarly, the efficiency of validation datasets can be limited if it reflects the same biases as the training data <span class="citation" data-cites="martinez-meyer2005">(<a href="#ref-martinez-meyer2005" role="doc-biblioref">Martinez-Meyer 2005</a>)</span>. Recall that this validation dataset is used to decide on the ideal conditions to train the final model before testing (and eventually, deployment); it is, therefore, extremely important to get it right. A large number of techniques to split data <span class="citation" data-cites="søgaard2021 vandergoot2021">(<a href="#ref-søgaard2021" role="doc-biblioref">Søgaard et al. 2021</a>; <a href="#ref-vandergoot2021" role="doc-biblioref">Goot 2021</a>)</span> use heuristics to minimize the risk of picking the wrong validation data.</p>
</section>
<section id="testing" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="testing"><span class="header-section-number">4.1.3</span> Testing</h3>
<p>The testing dataset is special. The model has <em>never</em> touched it. Not during training, and not for validation. For this reason, we can give it a very unique status: it is an analogue to data that are newly collected, and ready to be passed through the trained model in order to make a prediction.</p>
<p>The only difference between the testing set and actual new data is that, for the testing set, we know the labels. In other words, we can compare the model output to these labels, and this gives us an estimate of the model performance on future data. Assuming that this data selection was representative of the real data we will use for our model once it is trained, the performance on the validation set should be a good baseline for what to expect in production.</p>
<p>But this requires a trained model, and we sort of glossed over this step.</p>
<p>In order to come up with a trained model, it would be a strange idea not to use the validation data – they are, after all, holding information about the data we want to model! Once we have evaluated our model on the validation set, we can start the last round of training to produce the final model. We do this by training the model using everything <em>except</em> the testing data. This is an appropriate thing to do: because we have evaluated the model on the validation data, and assuming that it has a correct performance, we can expect that retraining the model on the validation data will not change the performance of the model.</p>
</section>
</section>
<section id="the-problem-cherry-blossom-phenology" class="level2 page-columns page-full" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="the-problem-cherry-blossom-phenology"><span class="header-section-number">4.2</span> The problem: cherry blossom phenology</h2>
<p>The cherry blossom tree (<em>Prunus</em>) is renowned for its impressive bloom, which happens from March to April. The blooming, and associated festivals, are of particular cultural significance <span class="citation" data-cites="moriuchi2019">(<a href="#ref-moriuchi2019" role="doc-biblioref">Moriuchi and Basil 2019</a>)</span>, and is therefore a cultural ecosystem service <span class="citation" data-cites="kosanic2020">(<a href="#ref-kosanic2020" role="doc-biblioref">Kosanic and Petzold 2020</a>)</span>. Climate change has a demonstrable effect on the date of first bloom on <em>Prunus</em> species in Japan <span class="citation" data-cites="primack2009">(<a href="#ref-primack2009" role="doc-biblioref">Primack, Higuchi, and Miller-Rushing 2009</a>)</span>, which can affect the sustainability of cherry blossom festivals in the short term <span class="citation" data-cites="sakurai2011">(<a href="#ref-sakurai2011" role="doc-biblioref">Sakurai et al. 2011</a>)</span>.</p>
<p>Long-term time series of the date of first bloom in Japan reveal that in the last decades, cherry blossom blooms earlier, which has been linked to, possibly, climate change and urbanization. <em>Prunus</em> species respond to environmental cues at the local level for their flowering <span class="citation" data-cites="mimet2009 ohashi2011a">(<a href="#ref-mimet2009" role="doc-biblioref">Mimet et al. 2009</a>; <a href="#ref-ohashi2011a" role="doc-biblioref">Ohashi et al. 2011</a>)</span>. The suspected causal mechanism is as follows: both global warming and urbanization lead to higher temperatures, which means a faster accumulation of degree days over the growing season, leading to an earlier bloom <span class="citation" data-cites="shi2017">(<a href="#ref-shi2017" role="doc-biblioref">Shi et al. 2017</a>)</span>. Indeed, the raw data presented in <a href="#fig-splits-rawdata" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> show that trees bloom early when the temperatures are higher; the data for phenology have been collected by <span class="citation" data-cites="aono2008">Aono and Kazui (<a href="#ref-aono2008" role="doc-biblioref">2008</a>)</span>, and the temperature reconstructions are from <span class="citation" data-cites="aono2009">Aono and Saito (<a href="#ref-aono2009" role="doc-biblioref">2009</a>)</span>.</p>
<div id="cell-fig-splits-rawdata" class="cell page-columns page-full" data-execution_count="4">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="5">
<div id="fig-splits-rawdata" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-splits-rawdata-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="crossvalidation_files/figure-html/fig-splits-rawdata-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig margin-caption" id="fig-splits-rawdata-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: The raw data show a negative relationship between the temperature in March, and the bloom time. This suggests that when the trees have accumulated enough temperature, they can bloom early. In a context of warming, we should therefore see earlier blooms with rising temperatures.
</figcaption>
</figure>
</div>
</div>
</div>
<p>With these data in hand (day of year with the first bloom, and smoothed reconstructed temperature in March), we can start thinking about this hypothesis. But by contrast with our simple strategy in <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>, this time, we will split our dataset into training, validation, and testing sets, as we discussed in the previous section. Yet there are many ways to split a dataset, and therefore before starting the analysis, we will have a look at a few of them.</p>
</section>
<section id="strategies-to-split-data" class="level2 page-columns page-full" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="strategies-to-split-data"><span class="header-section-number">4.3</span> Strategies to split data</h2>
<p>Before seeing examples of strategies for cross-validation, it is important to consider the high-level perspective of the way we will perform the entire training sequence. First, we need to keep a testing dataset. Depending on the problem, it may be <em>feasible</em> or <em>desirable</em> to use an external testing dataset <span class="citation" data-cites="homeyer2022">(<a href="#ref-homeyer2022" role="doc-biblioref">Homeyer et al. 2022</a>)</span>. In problems for which the volume of data is limited (the 99.99% of biodiversity applications that do not involve metagenomics of remote sensing), this is almost impossible, and therefore we need to resort to removing a proportion of the data. It means that collected data will never be used for training, which is not ideal, but what we gain in return is a fairer appraisal of the performance of the model, which is a really advantageous trade-off. When the testing data are removed, we can start splitting the rest of the data in testing and validation sets. This can involve two broad categories of families: exhaustive splits (all data are used for training and evaluation), and non-exhaustive splits (the opposite; for once, the terminology makes sense!).</p>
<section id="holdout" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="holdout"><span class="header-section-number">4.3.1</span> Holdout</h3>
<p>The holdout method is what we used in <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>, in which we randomly selected some observations to be part of the validation data (which was, in practice, a testing dataset in this example), and kept the rest to serve as the training data. Holdout cross-validation is possibly the simplest technique, but it suffers from a few drawbacks.</p>
<p>The model is only trained for one split of the data, and similarly only evaluated for one split of the data. There is, therefore, a chance to sample a particularly bad combination of the data that lead to erroneous results. Attempts to quantify the importance of the predictors are likely to give particularly unstable results, as the noise introduced by picking a single random subset will not be smoothed out by multiple attempts.</p>
<p>In addition, as <span class="citation" data-cites="hawkins2003">Hawkins, Basak, and Mills (<a href="#ref-hawkins2003" role="doc-biblioref">2003</a>)</span> point out, holdout validation is particularly wasteful in data-limited settings, where there are fewer than hundreds of observations. The reason is that the holdout dataset will <em>never</em> contribute to training, and assuming the data are split 80/20, one out of five observations will not contribute to the model. Other cross-validation schemes presented in this section will allow observations to be used both for training and validation.</p>
</section>
<section id="leave-p-out" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="leave-p-out"><span class="header-section-number">4.3.2</span> Leave-p-out</h3>
<p>In leave-<em>p</em>-out cross-validation (LpOCV), starting from a dataset on <span class="math inline">\(n\)</span> observations, we pick <span class="math inline">\(p\)</span> at random to serve as validation data, and <span class="math inline">\(n-p\)</span> to serve as the training dataset. This process is then repeated <em>exhaustively</em>, which is to say we split the dataset in every possible way that gives <span class="math inline">\(p\)</span> and <span class="math inline">\(n-p\)</span> observations, for a set value of <span class="math inline">\(p\)</span>. The model is then trained on the <span class="math inline">\(n-p\)</span> observations, and validated on the <span class="math inline">\(p\)</span> observations for validation, and the performance (or loss) is averaged to give the model performance before testing.</p>
<p><span class="citation" data-cites="celisse2014">Celisse (<a href="#ref-celisse2014" role="doc-biblioref">2014</a>)</span> points out that <span class="math inline">\(p\)</span> has to be large enough (relative to the sample size <span class="math inline">\(n\)</span>) to overcome the propensity of the model to overfit on a small training dataset. One issue with LpOCV is that the number of combinations is potentially very large. It is, in fact, given by the binomial coefficient <span class="math inline">\(\binom{n}{p}\)</span>, which gets unreasonably large even for small datasets. For example, running LpOCV on <span class="math inline">\(n=150\)</span> observations, leaving out <span class="math inline">\(p=10\)</span> for validation every time, would require to train the model about <span class="math inline">\(10^{15}\)</span> times. Assuming we can train the model in <span class="math inline">\(10^{-3}\)</span> seconds, the entire process would require 370 centuries.</p>
<p>Oh well.</p>
</section>
<section id="leave-one-out" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="leave-one-out"><span class="header-section-number">4.3.3</span> Leave-one-out</h3>
<p>The leave-one-out cross-validation (LOOCV) is a special case of LpOCV with <span class="math inline">\(p=1\)</span>. Note that it is a lot faster to run than LpOCV, because <span class="math inline">\(\binom{n}{1}=n\)</span>, and so the validation step runs in <span class="math inline">\(\mathcal{O}(n)\)</span> (LpOCV runs in <span class="math inline">\(\mathcal{O}(n!)\)</span>). LOOCV is also an <em>exhaustive</em> cross-validation technique, as every possible way to split the dataset will be used for training and evaluation.</p>
</section>
<section id="k-fold" class="level3 page-columns page-full" data-number="4.3.4">
<h3 data-number="4.3.4" class="anchored" data-anchor-id="k-fold"><span class="header-section-number">4.3.4</span> k-fold</h3>
<p>One of the most frequent cross-validation scheme is k-fold cross-validation. Under this approach, the dataset is split into <span class="math inline">\(k\)</span> equal parts (and so when <span class="math inline">\(k = n\)</span>, this is also equivalent to LOOCV). Like with LOOCV, one desirable property of k-fold cross-validation is that each observation is used <em>exactly</em> one time to evaluate the model , and <em>exactly</em> <span class="math inline">\(k-1\)</span> times to train it.</p>
<p>But by contrast with the holdout validation approach, <em>all</em> observations are used to train the model.</p>
<p>When the data have some specific structure, it can be a good thing to manipulate the splits in order to maintain this structure. For example, <span class="citation" data-cites="bergmeir2012">Bergmeir and Benítez (<a href="#ref-bergmeir2012" role="doc-biblioref">2012</a>)</span> use temporal blocks for validation of time series, and retain the last part of the series for testing (we illustrate this in <a href="#fig-splits-illustration" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>). For spatial data, <span class="citation" data-cites="hijmans2012">Hijmans (<a href="#ref-hijmans2012" role="doc-biblioref">2012</a>)</span> suggests the use of a null model based on distance to training sites to decide on how to split the data; <span class="citation" data-cites="valavi2018">Valavi et al. (<a href="#ref-valavi2018" role="doc-biblioref">2018</a>)</span> have designed specific k-fold cross-validation schemes for species distribution models. These approaches all belong to the family of <em>stratified</em> k-fold cross-validation <span class="citation" data-cites="zeng2000">(<a href="#ref-zeng2000" role="doc-biblioref">Zeng and Martinez 2000</a>)</span>.</p>
<div id="cell-fig-splits-illustration" class="cell page-columns page-full" data-execution_count="7">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="8">
<div id="fig-splits-illustration" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-splits-illustration-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="crossvalidation_files/figure-html/fig-splits-illustration-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig margin-caption" id="fig-splits-illustration-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: An illustration of a series of folds on a timeseries. The grey data are used for training, the green data for validation, and the purple data are kept for testing. Note that in this context, we sometimes use the future to validate on the past (look at the first fold!), but this is acceptable for reasons explained in the text.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The appropriate value of <span class="math inline">\(k\)</span> is often an unknown. It is common to use <span class="math inline">\(k = 10\)</span> as a starting point (tenfold cross-validation), but other values are justifiable based on data volume, or complexity of the model training, to name a few.</p>
</section>
<section id="sec-crossvalidation-montecarlo" class="level3" data-number="4.3.5">
<h3 data-number="4.3.5" class="anchored" data-anchor-id="sec-crossvalidation-montecarlo"><span class="header-section-number">4.3.5</span> Monte-Carlo</h3>
<p>One limitation of k-fold cross-validation is that the number of splits is limited by the amount of observations, especially if we want to ensure that there are enough samples in the validation data. To compensate for this, Monte-Carlo cross-validation is essentially the application (and averaging) of holdout validation an arbitrary number of times. Furthermore, the training and validation datasets can be constructed in order to account for specific constraints in the dataset, giving more flexibility than k-fold cross-validation <span class="citation" data-cites="roberts2017">(<a href="#ref-roberts2017" role="doc-biblioref">Roberts et al. 2017</a>)</span>. When the (computational) cost of training the model is high, and the dataset has specific structural constraints, Monte-Carlo cross-validation is a good way to generate data for hyperparameters tuning.</p>
<p>One issue with Monte-Carlo cross-validation is that we lose the guarantee that every observation will be used for training at least once (and similarly for validation). Trivially, this becomes less of an issue when we increase the number of replications, but then this suffers from the same issues as LpOCV, namely the unreasonable computational requirements.</p>
</section>
</section>
<section id="application-when-do-cherry-blossom-bloom" class="level2 page-columns page-full" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="application-when-do-cherry-blossom-bloom"><span class="header-section-number">4.4</span> Application: when do cherry blossom bloom?</h2>
<p>The model we will train for this section is really simple: <span class="math inline">\(\text{bloom day} = m \times \text{temperature} + b\)</span>. This is a linear model, and one with a nice, direct biological interpretation: the average (baseline) day of bloom is <span class="math inline">\(b\)</span>, and each degree of temperature expected in March adds <span class="math inline">\(m\)</span> days to the bloom date. At this point, we <em>might</em> start thinking about the distribution of the response, and what type of GLM we should used, but no. Not today. Today, we want to iterate quickly, and so we will start with a model that is exactly as simple as it needs to be: this is, in our case, linear regression.</p>
<p>At this point, we may be tempted to think a little more deeply about the variables and the structure of the model, to express the bloom day as a departure from the expected value, and similarly with the temperature, using for example the <em>z</em>-score. This is a transformation we will apply starting from <a href="classification.html" class="quarto-xref"><span>Chapter&nbsp;5</span></a>, but in order to apply it properly, we need to consider some elements that will be introduced in <a href="variableselection.html#sec-leakage" class="quarto-xref"><span>Section&nbsp;6.2</span></a>. For this reason, we will not apply any transformation to the data yet; feel free to revisit this exercise after reading through <a href="variableselection.html#sec-leakage" class="quarto-xref"><span>Section&nbsp;6.2</span></a>.</p>
<p>This approach (start from a model that is suspiciously simple) is a good thing, for more than a few reasons. First, it gives us a baseline to compare more complicated models against. Second, it means that we do not need to focus on the complexity of the code (and the model) when building a pipeline for the analysis. Finally, and most importantly, it gives us a result very rapidly, which enables a loop of iterative model refinement on a very short timescale. Additionally, at least for this example, the simple models often work well enough to support a discussion of the model and training process.</p>
<section id="performance-evaluation" class="level3 page-columns page-full" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="performance-evaluation"><span class="header-section-number">4.4.1</span> Performance evaluation</h3>
<p>We can visualize the results of our model training and assessment process. These results are presented in <a href="#fig-splits-performance" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> (as well as in <a href="#tbl-splits-performance-summary" class="quarto-xref">Table&nbsp;<span>4.2</span></a>, if you want to see the standard deviation across all splits), and follow the same color-coding convention we have used so far. All three loss measures presented here express their loss in the units of the response variable, which in this case is the day of the year where the bloom was recorded. These results show that our trained model achieves a loss of the order of a day or two in the testing data, which sounds really good!</p>
<div id="cell-fig-splits-performance" class="cell page-columns page-full" data-execution_count="10">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="11">
<div id="fig-splits-performance" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-splits-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="crossvalidation_files/figure-html/fig-splits-performance-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig margin-caption" id="fig-splits-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: Visualisation of the model performance for three loss functions (MA, RMSE, MBE, as defined in <a href="gradientdescent.html#tbl-gradientdescent-regressionloss" class="quarto-xref">Table&nbsp;<span>3.1</span></a>). The colors are the same as in <a href="#fig-splits-illustration" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>, <em>i.e.</em> grey for the training data, green for the validation data, and purple for the testing data.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Yet it is important to contextualize these results. What does it means for our prediction to be correct plus or minus two days? There are at least two important points to consider.</p>
<div class="cell" data-execution_count="11">
<div id="tbl-splits-performance-summary" class="cell anchored" data-execution_count="11">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-splits-performance-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header headerLastRow">
<th style="text-align: right;" data-quarto-table-cell-role="th">Dataset</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Measure</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Loss (avg.)</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Loss (std. dev.)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">MAE</td>
<td style="text-align: right;">1.696</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">MAE</td>
<td style="text-align: right;">2.2397</td>
<td style="text-align: right;">0.0482364</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">MAE</td>
<td style="text-align: right;">2.26331</td>
<td style="text-align: right;">0.421513</td>
</tr>
<tr class="even">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">MBE</td>
<td style="text-align: right;">0.0971036</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">MBE</td>
<td style="text-align: right;">9.8278e-15</td>
<td style="text-align: right;">1.15597e-14</td>
</tr>
<tr class="even">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">MBE</td>
<td style="text-align: right;">0.000419595</td>
<td style="text-align: right;">0.910229</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">MSE</td>
<td style="text-align: right;">4.49123</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">MSE</td>
<td style="text-align: right;">8.04855</td>
<td style="text-align: right;">0.32487</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">MSE</td>
<td style="text-align: right;">8.24897</td>
<td style="text-align: right;">2.93094</td>
</tr>
<tr class="even">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">RMSE</td>
<td style="text-align: right;">2.11925</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">RMSE</td>
<td style="text-align: right;">2.83648</td>
<td style="text-align: right;">0.0570941</td>
</tr>
<tr class="even">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">RMSE</td>
<td style="text-align: right;">2.82514</td>
<td style="text-align: right;">0.545232</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="table quarto-float-caption quarto-float-tbl" id="tbl-splits-performance-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4.2: TODO
</figcaption>
</figure>
</div>
</div>
<p>First, what are we predicting? Our response variable is not <em>really</em> the day of the bloom, but is rather a smoothed average looking back some years, and looking ahead some years too. For this reason, we are removing a lot of the variability in the underlying time series. This is not necessarily a bad thing, especially if we are looking for a trend at a large temporal scale, but it means that we should not interpret our results at a scale lower than the duration of the window we use for averaging.</p>
<p>Second, what difference <em>does</em> a day make? <a href="#fig-splits-rawdata" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> shows that most of the days of bloom happen between day-of-year 100 and day-of-year 110. Recall that the MAE is measured by taking the average absolute error – a mistake of 24 hours is 10% of this interval! This is an example of how thinking about the units of the loss function we use for model evaluation can help us contextualize the predictions, and in particular how actionable they can be.</p>
</section>
<section id="model-predictions" class="level3 page-columns page-full" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="model-predictions"><span class="header-section-number">4.4.2</span> Model predictions</h3>
<p>The predictions of our model are presented in <a href="#fig-splits-prediction" class="quarto-xref">Figure&nbsp;<span>4.4</span></a>; these are the predictions of the <em>final</em> model, that is, the model that we trained on everything <em>except</em> the testing data, and for which we can get the performance by looking at <a href="#fig-splits-performance" class="quarto-xref">Figure&nbsp;<span>4.3</span></a>.</p>
<div id="cell-fig-splits-prediction" class="cell page-columns page-full" data-execution_count="12">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="13">
<div id="fig-splits-prediction" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-splits-prediction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="crossvalidation_files/figure-html/fig-splits-prediction-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig margin-caption" id="fig-splits-prediction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: Overview of the fit of the final model (trained on all the training examples), visualized as the time series. Note that the year was not used as a variable in the model. The purple part of the prediction corresponds to the prediction of the model for the testing data, which are zoomed-in on in <a href="#fig-splits-detail" class="quarto-xref">Figure&nbsp;<span>4.5</span></a>. Although the model captures the cycles reasonably well, it tends to smooth out a lot of extreme events.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The question we now need to answer is: is our model doing a good job? We can start thinking about this question in a very qualitative way: yes, it does a goob job at drawing a line that, through time, goes right through the original data more often that it doesn’t. As far as validation goes, it maybe underestimates the drop in the response variable (it predicts the bloom a little later), but maybe there are long-term effects, expressed over the lifetime of the tree (the first bloom usually takes places after 6 or 7 growth seasons), that we do not account for.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Think about the structure of linear models. Can we use information about the previous years in our model? Would there be a risk associated to adding more parameters?</p>
</div></div><p>Our model tends to smooth out some of the variation; it does not predict bloom dates before day of year 100, or after day of year 108, although they do happen. This may not be a trivial under-prediction: some of these cycles leading to very early/late bloom can take place over a century, meaning that our model could be consistently wrong (which is to say, wrong with the same bias) for dozens of years in a row.</p>
</section>
<section id="sec-crossvalidation-fitness" class="level3 page-columns page-full" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="sec-crossvalidation-fitness"><span class="header-section-number">4.4.3</span> Is our model good, then?</h3>
<p>The answer is, it depends. Models are neither good, nor bad. They are either fit, or unfit, for a specific purpose.</p>
<p>If the purpose is to decide when to schedule a one-day trip to see the cherry blossom bloom, our model is not really fit – looking at the predictions, it gets within a day of the date of bloom (but oh, by the way, this is an average over almost a decade!) about 15% of the time, which jumps up to almost 30% if you accept a two-days window of error.</p>
<p>If the purpose is to look at long-time trends in the date of bloom, then our model actually works rather well. It does under-estimate the amplitude of the cycles, but not by a large amount. In fact, we could probably stretch the predictions a little, applying a little correction factor, and have a far more interesting model.</p>
<p>We will often be confronted to this question when working with prediction. There is not really a criteria for “good”, only a series of compromises and judgment calls about “good enough”. This is important. It reinforces the imperative of keeping the practice of data science connected to the domain knowledge, as ultimately, a domain expert will have to settle on whether to use a model or not.</p>
<div id="cell-fig-splits-detail" class="cell page-columns page-full" data-execution_count="13">
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="14">
<div id="fig-splits-detail" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-splits-detail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="crossvalidation_files/figure-html/fig-splits-detail-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig margin-caption" id="fig-splits-detail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: Overview of the model predictions on the testing data. Note that the model still smoothes out some of the extreme values. More importantly, it seems that it is under-estimating the sharp decline in the day of first bloom that happens starting in 1950; this suggests that the model is not adequately capturing important processes shaping the data.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">4.5</span> Conclusion</h2>
<p>In this chapter, we trained a linear regression model to predict the day of bloom of cherry blossom trees based on the predicted temperature in March. Although the model makes a reasonable error (of the order of a few days), a deeper investigation of the amplitude of this error compared to the amplitude of the response variable, and of the comparison of extreme values in the prediction and in the data, led us to a more cautious view about the usefulness of this model. In practice, if we really wanted to solve this problem, this is the point where we would either add variables, or try another regression algorithm, or both.</p>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aono2008" class="csl-entry" role="listitem">
Aono, Yasuyuki, and Keiko Kazui. 2008. <span>“Phenological Data Series of Cherry Tree Flowering in Kyoto, Japan, and Its Application to Reconstruction of Springtime Temperatures Since the 9th Century.”</span> <em>International Journal of Climatology</em> 28 (7): 905–14. <a href="https://doi.org/10.1002/joc.1594">https://doi.org/10.1002/joc.1594</a>.
</div>
<div id="ref-aono2009" class="csl-entry" role="listitem">
Aono, Yasuyuki, and Shizuka Saito. 2009. <span>“Clarifying Springtime Temperature Reconstructions of the Medieval Period by Gap-Filling the Cherry Blossom Phenological Data Series at Kyoto, Japan.”</span> <em>International Journal of Biometeorology</em> 54 (2): 211–19. <a href="https://doi.org/10.1007/s00484-009-0272-x">https://doi.org/10.1007/s00484-009-0272-x</a>.
</div>
<div id="ref-bellocchi2010" class="csl-entry" role="listitem">
Bellocchi, Gianni, Mike Rivington, Marcello Donatelli, and Keith Matthews. 2010. <span>“Validation of Biophysical Models: Issues and Methodologies. A Review.”</span> <em>Agronomy for Sustainable Development</em> 30 (1): 109–30. <a href="https://doi.org/10.1051/agro/2009001">https://doi.org/10.1051/agro/2009001</a>.
</div>
<div id="ref-bergmeir2012" class="csl-entry" role="listitem">
Bergmeir, Christoph, and José M. Benítez. 2012. <span>“On the Use of Cross-Validation for Time Series Predictor Evaluation.”</span> <em>Information Sciences</em> 191 (May): 192–213. <a href="https://doi.org/10.1016/j.ins.2011.12.028">https://doi.org/10.1016/j.ins.2011.12.028</a>.
</div>
<div id="ref-celisse2014" class="csl-entry" role="listitem">
Celisse, Alain. 2014. <span>“Optimal Cross-Validation in Density Estimation with the <span>$</span>l<span>^</span><span></span>2<span></span><span>$</span>-Loss.”</span> <em>The Annals of Statistics</em> 42 (5). <a href="https://doi.org/10.1214/14-aos1240">https://doi.org/10.1214/14-aos1240</a>.
</div>
<div id="ref-vandergoot2021" class="csl-entry" role="listitem">
Goot, Rob van der. 2021. <span>“We Need to Talk about Train-Dev-Test Splits.”</span> <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>. <a href="https://doi.org/10.18653/v1/2021.emnlp-main.368">https://doi.org/10.18653/v1/2021.emnlp-main.368</a>.
</div>
<div id="ref-hawkins2003" class="csl-entry" role="listitem">
Hawkins, Douglas M., Subhash C. Basak, and Denise Mills. 2003. <span>“Assessing Model Fit by Cross-Validation.”</span> <em>Journal of Chemical Information and Computer Sciences</em> 43 (2): 579–86. <a href="https://doi.org/10.1021/ci025626i">https://doi.org/10.1021/ci025626i</a>.
</div>
<div id="ref-hijmans2012" class="csl-entry" role="listitem">
Hijmans, Robert J. 2012. <span>“Cross-Validation of Species Distribution Models: Removing Spatial Sorting Bias and Calibration with a Null Model.”</span> <em>Ecology</em> 93 (3): 679–88. <a href="https://doi.org/10.1890/11-0826.1">https://doi.org/10.1890/11-0826.1</a>.
</div>
<div id="ref-homeyer2022" class="csl-entry" role="listitem">
Homeyer, André, Christian Geißler, Lars Ole Schwen, Falk Zakrzewski, Theodore Evans, Klaus Strohmenger, Max Westphal, et al. 2022. <span>“Recommendations on Compiling Test Datasets for Evaluating Artificial Intelligence Solutions in Pathology.”</span> <em>Modern Pathology</em> 35 (12): 1759–69. <a href="https://doi.org/10.1038/s41379-022-01147-y">https://doi.org/10.1038/s41379-022-01147-y</a>.
</div>
<div id="ref-kosanic2020" class="csl-entry" role="listitem">
Kosanic, Aleksandra, and Jan Petzold. 2020. <span>“A Systematic Review of Cultural Ecosystem Services and Human Wellbeing.”</span> <em>Ecosystem Services</em> 45 (October): 101168. <a href="https://doi.org/10.1016/j.ecoser.2020.101168">https://doi.org/10.1016/j.ecoser.2020.101168</a>.
</div>
<div id="ref-martinez-meyer2005" class="csl-entry" role="listitem">
Martinez-Meyer, Enrique. 2005. <span>“Climate Change and Biodiversity: Some Considerations in Forecasting Shifts in Species’ Potential Distributions.”</span> <em>Biodiversity Informatics</em> 2 (0). <a href="https://doi.org/10.17161/bi.v2i0.8">https://doi.org/10.17161/bi.v2i0.8</a>.
</div>
<div id="ref-mimet2009" class="csl-entry" role="listitem">
Mimet, A., V. Pellissier, H. Quénol, R. Aguejdad, V. Dubreuil, and F. Rozé. 2009. <span>“Urbanisation Induces Early Flowering: Evidence from Platanus Acerifolia and Prunus Cerasus.”</span> <em>International Journal of Biometeorology</em> 53 (3): 287–98. <a href="https://doi.org/10.1007/s00484-009-0214-7">https://doi.org/10.1007/s00484-009-0214-7</a>.
</div>
<div id="ref-moriuchi2019" class="csl-entry" role="listitem">
Moriuchi, Emi, and Michael Basil. 2019. <span>“The Sustainability of Ohanami Cherry Blossom Festivals as a Cultural Icon.”</span> <em>Sustainability</em> 11 (6): 1820. <a href="https://doi.org/10.3390/su11061820">https://doi.org/10.3390/su11061820</a>.
</div>
<div id="ref-newey2015" class="csl-entry" role="listitem">
Newey, Scott, Paul Davidson, Sajid Nazir, Gorry Fairhurst, Fabio Verdicchio, R. Justin Irvine, and René van der Wal. 2015. <span>“Limitations of Recreational Camera Traps for Wildlife Management and Conservation Research: A Practitioner<span>’</span>s Perspective.”</span> <em>Ambio</em> 44 (S4): 624–35. <a href="https://doi.org/10.1007/s13280-015-0713-1">https://doi.org/10.1007/s13280-015-0713-1</a>.
</div>
<div id="ref-ohashi2011a" class="csl-entry" role="listitem">
Ohashi, Yukitaka, Hiroshi Kawakami, Yoshinori Shigeta, Hiroshi Ikeda, and Nobuko Yamamoto. 2011. <span>“The Phenology of Cherry Blossom (Prunus Yedoensis <span>“</span>Somei-Yoshino<span>”</span>) and the Geographic Features Contributing to Its Flowering.”</span> <em>International Journal of Biometeorology</em> 56 (5): 903–14. <a href="https://doi.org/10.1007/s00484-011-0496-4">https://doi.org/10.1007/s00484-011-0496-4</a>.
</div>
<div id="ref-primack2009" class="csl-entry" role="listitem">
Primack, Richard B., Hiroyoshi Higuchi, and Abraham J. Miller-Rushing. 2009. <span>“The Impact of Climate Change on Cherry Trees and Other Species in Japan.”</span> <em>Biological Conservation</em> 142 (9): 1943–49. <a href="https://doi.org/10.1016/j.biocon.2009.03.016">https://doi.org/10.1016/j.biocon.2009.03.016</a>.
</div>
<div id="ref-roberts2017" class="csl-entry" role="listitem">
Roberts, David R., Volker Bahn, Simone Ciuti, Mark S. Boyce, Jane Elith, Gurutzeta Guillera-Arroita, Severin Hauenstein, et al. 2017. <span>“Cross<span>-</span>Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure.”</span> <em>Ecography</em> 40 (8): 913–29. <a href="https://doi.org/10.1111/ecog.02881">https://doi.org/10.1111/ecog.02881</a>.
</div>
<div id="ref-sakurai2011" class="csl-entry" role="listitem">
Sakurai, Ryo, Susan K. Jacobson, Hiromi Kobori, Richard Primack, Kohei Oka, Naoya Komatsu, and Ryo Machida. 2011. <span>“Culture and Climate Change: Japanese Cherry Blossom Festivals and Stakeholders<span>’</span> Knowledge and Attitudes about Global Climate Change.”</span> <em>Biological Conservation</em> 144 (1): 654–58. <a href="https://doi.org/10.1016/j.biocon.2010.09.028">https://doi.org/10.1016/j.biocon.2010.09.028</a>.
</div>
<div id="ref-shi2017" class="csl-entry" role="listitem">
Shi, Peijian, Zhenghong Chen, Gadi V. P. Reddy, Cang Hui, Jianguo Huang, and Mei Xiao. 2017. <span>“Timing of Cherry Tree Blooming: Contrasting Effects of Rising Winter Low Temperatures and Early Spring Temperatures.”</span> <em>Agricultural and Forest Meteorology</em> 240-241 (June): 78–89. <a href="https://doi.org/10.1016/j.agrformet.2017.04.001">https://doi.org/10.1016/j.agrformet.2017.04.001</a>.
</div>
<div id="ref-søgaard2021" class="csl-entry" role="listitem">
Søgaard, Anders, Sebastian Ebert, Jasmijn Bastings, and Katja Filippova. 2021. <span>“We Need to Talk about Random Splits.”</span> <em>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>. <a href="https://doi.org/10.18653/v1/2021.eacl-main.156">https://doi.org/10.18653/v1/2021.eacl-main.156</a>.
</div>
<div id="ref-valavi2018" class="csl-entry" role="listitem">
Valavi, Roozbeh, Jane Elith, José J. Lahoz-Monfort, and Gurutzeta Guillera-Arroita. 2018. <span>“Block CV : An r Package for Generating Spatially or Environmentally Separated Folds for <span><em>k</em></span> <span>-</span>Fold Cross<span>-</span>Validation of Species Distribution Models.”</span> Edited by David Warton. <em>Methods in Ecology and Evolution</em> 10 (2): 225–32. <a href="https://doi.org/10.1111/2041-210x.13107">https://doi.org/10.1111/2041-210x.13107</a>.
</div>
<div id="ref-zeng2000" class="csl-entry" role="listitem">
Zeng, Xinchuan, and Tony R. Martinez. 2000. <span>“Distribution-Balanced Stratified Cross-Validation for Accuracy Estimation.”</span> <em>Journal of Experimental &amp; Theoretical Artificial Intelligence</em> 12 (1): 1–12. <a href="https://doi.org/10.1080/095281300146272">https://doi.org/10.1080/095281300146272</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work is licensed under the <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International License</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>