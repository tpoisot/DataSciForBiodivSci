<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.330">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science for Biodiversity Scientists - 4&nbsp; Testing, training, validating</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": true,
  "collapse-after": 1,
  "panel-placement": "start",
  "type": "overlay",
  "limit": 10,
  "keyboard-shortcut": [
    null
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/splits.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Testing, training, validating</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Data Science for Biodiversity Scientists</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Data-Science-for-Biodiversity-Scientists.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Data-Science-for-Biodiversity-Scientists.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div id="quarto-search" class="quarto-navigation-tool px-1" title="Search"></div>
</div>
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/gradientdescent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Gradient descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/splits.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Testing, training, validating</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/leakage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data leakage</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Supervised classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/variableselection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Variable selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/learningcurves.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Learning curves and moving thresholds</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/varimp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Understanding the effects of variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#how-can-we-split-a-dataset" id="toc-how-can-we-split-a-dataset" class="nav-link active" data-scroll-target="#how-can-we-split-a-dataset"><span class="header-section-number">4.1</span> How can we split a dataset?</a>
  <ul class="collapse">
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training"><span class="header-section-number">4.1.1</span> Training</a></li>
  <li><a href="#validating" id="toc-validating" class="nav-link" data-scroll-target="#validating"><span class="header-section-number">4.1.2</span> Validating</a></li>
  <li><a href="#testing" id="toc-testing" class="nav-link" data-scroll-target="#testing"><span class="header-section-number">4.1.3</span> Testing</a></li>
  </ul></li>
  <li><a href="#the-problem-phenology-of-cherry-blossom" id="toc-the-problem-phenology-of-cherry-blossom" class="nav-link" data-scroll-target="#the-problem-phenology-of-cherry-blossom"><span class="header-section-number">4.2</span> The problem: phenology of cherry blossom</a></li>
  <li><a href="#strategies-to-split-data" id="toc-strategies-to-split-data" class="nav-link" data-scroll-target="#strategies-to-split-data"><span class="header-section-number">4.3</span> Strategies to split data</a>
  <ul class="collapse">
  <li><a href="#holdout" id="toc-holdout" class="nav-link" data-scroll-target="#holdout"><span class="header-section-number">4.3.1</span> Holdout</a></li>
  <li><a href="#leave-p-out" id="toc-leave-p-out" class="nav-link" data-scroll-target="#leave-p-out"><span class="header-section-number">4.3.2</span> Leave-p-out</a></li>
  <li><a href="#leave-one-out" id="toc-leave-one-out" class="nav-link" data-scroll-target="#leave-one-out"><span class="header-section-number">4.3.3</span> Leave-one-out</a></li>
  <li><a href="#k-fold" id="toc-k-fold" class="nav-link" data-scroll-target="#k-fold"><span class="header-section-number">4.3.4</span> k-fold</a></li>
  <li><a href="#monte-carlo" id="toc-monte-carlo" class="nav-link" data-scroll-target="#monte-carlo"><span class="header-section-number">4.3.5</span> Monte-Carlo</a></li>
  </ul></li>
  <li><a href="#application-when-do-cherry-blossom-bloom" id="toc-application-when-do-cherry-blossom-bloom" class="nav-link" data-scroll-target="#application-when-do-cherry-blossom-bloom"><span class="header-section-number">4.4</span> Application: when do cherry blossom bloom?</a>
  <ul class="collapse">
  <li><a href="#performance-evaluation" id="toc-performance-evaluation" class="nav-link" data-scroll-target="#performance-evaluation"><span class="header-section-number">4.4.1</span> Performance evaluation</a></li>
  <li><a href="#model-predictions" id="toc-model-predictions" class="nav-link" data-scroll-target="#model-predictions"><span class="header-section-number">4.4.2</span> Model predictions</a></li>
  <li><a href="#sec-splits-fitness" id="toc-sec-splits-fitness" class="nav-link" data-scroll-target="#sec-splits-fitness"><span class="header-section-number">4.4.3</span> Is our model good, then?</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-splits" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Testing, training, validating</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>

<p>In <span class="quarto-unresolved-ref">?sec-kmeans</span>, we were very lucky. Because we applied an unsupervised method, we didn’t really have a target to compare to the output. Whatever classification we got, we had to live with it. It was incredibly freeing. Sadly, in most applications, we will have to compare our predictions to data, and data are incredibly vexatious. In this chapter, we will develop intuitions on the notions of training, testing, and validation; we will further think about data leakage, why it is somehow worse than it sounds, and how to protect against it.</p>
<p>In a sense, we started thinking about these concepts in <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>; specifically, we came up with a way to optimize the parameters of our model (<em>i.e.</em> of <em>training</em> our model) based on a series of empirical observations, and a criteria for what a “good fit” is. We further appraised the performance of our model by measuring the loss (our measure of how good the fit is) on a dataset that was not accessible during training.</p>
<section id="how-can-we-split-a-dataset" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="how-can-we-split-a-dataset"><span class="header-section-number">4.1</span> How can we split a dataset?</h2>
<p>There is a much more important question to ask first: <em>why</em> do we split a dataset? In a sense, answering this question echoes the discussion we started in <strong>TODO REG MOD</strong>, because the purpose of splitting a dataset is to ensure we can train and evaluate it properly, in order to deliver the best possible model.</p>
<p>When a model is trained, it has learned from the data, we have tuned its hyper-parameters to ensure that it learned with the best possible conditions, and we have applied a measure of performance after the entire process to communicate how well our model works. These three tasks require three different datasets, and this is the purpose of splitting our data into groups.</p>
<p>One of the issues when reading about splitting data is that the terminology can be muddy. For example, what constitutes a testing and validation set can largely be a matter of perspective. In many instances, testing and validation are used interchangeably, and this book is no exception. Nevertheless, it helps to settle on a few guidelines here, before going into the details of what each dataset constitutes and how to assemble it.</p>
<p>The training data are examples that are given to the model during the training process. This one has no ambiguities. aside from the fact that it is defined by substraction, in a sense, as whatever is left of the original data after we set aside testing and validation sets.</p>
<p>The testing data are used at the end of the process, to measure the performance of a trained model with tuned hyper-parameters. If the training data are the lectures, testing data are the final exam: we can measure the performance of the model on this dataset and report it as the model performance we can expect when applying the model to new data. There is a very important, chapter-long, caveat about this last point, related to the potential of information leak between datasets, which is covered in <strong>TODO LEAKAGE</strong>.</p>
<p>The validation data are used in-between, as part of the training process. They are (possibly) a subset of the training data that we use internally to check the performance of the model, often in order to tune its hyper-parameters, or as a way to report on the over-fitting of the model during the training process.</p>
<p>The difference between testing and validation is largely a difference of <em>intent</em>. When we want to provide an a posteriori assessment of the model performance, the dataset we use to determine this performance is a testing dataset. When we want to optimize some aspect of the model, the data we use for this are the validation data. With this high-level perspective in mind, let’s look at each of these datasets in turn. The differences between these three datasets are summarized in <a href="#tbl-splits-models" class="quarto-xref">Table&nbsp;<span>4.1</span></a>.</p>
<div id="tbl-splits-models" class="anchored">
<table class="table">
<caption>Table&nbsp;4.1: gfkdf jdshgl dsjg d.&nbsp;Information in the “Data used for training” column refer to the data that have been used to train the model when calculating its performance.</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Dataset</th>
<th>Trains</th>
<th>Purpose</th>
<th>Data for performance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training</td>
<td>yes</td>
<td>train model</td>
<td></td>
</tr>
<tr class="even">
<td>Validation</td>
<td></td>
<td>validate during training</td>
<td>training data only</td>
</tr>
<tr class="odd">
<td>Testing</td>
<td></td>
<td>estimates of future performance</td>
<td>all except testing</td>
</tr>
</tbody>
</table>
</div>
<section id="training" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="training"><span class="header-section-number">4.1.1</span> Training</h3>
<p>In data science (in applied machine learning in particular), we do <em>fit</em> models. We <em>train</em> them. This is an important difference: training is an iterative process, that we can repeat, optimize, and tweak. The outcome of training and the outcome of fitting are essentially the same (a model that is parameterized to work as well as possible on a given dataset), but it is good practice to adopt the language of a field, and the language of data science emphasizes the different practices in model training.</p>
<p>Training, to provide a general definition, is the action of modifying the parameters of a model, based on knowledge of the data, and the error that results from using the current parameter values. In <a href="gradientdescent.html" class="quarto-xref"><span>Chapter&nbsp;3</span></a>, for example, we will see how to train a linear model using the technique of gradient descent. Our focus in this chapter is not on the methods we use for training, but on the data that are required to train a model.</p>
<p>Training a model is a process akin to rote learning: we will present the same input, and the same expected responses, many times over, and we will find ways for the error on each response to decrease.</p>
<p>In order to initiate this process, we need an untrained model. Untrained, in this context, refers to a model that has not been trained <em>on the specific problem</em> we are addressing; the model may have been trained on a different problem (for example, we want to predict the distribution of a species based on a GLM trained on a phylogenetically related species). It is important to note that by “training the model”, what we really mean is “change the structure of the parameters until the output looks right”. For example, assuming a simple linear model like <span class="math inline">\(c(X) = \beta_0 + \beta_1X_1 + \beta_2X_2\)</span>, training this model would lead to changes in the values of <span class="math inline">\(\beta\)</span>, but not to the consideration of a new model <span class="math inline">\(c(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_1X_2\)</span>. Comparing models is (often) the point of validation, which we will address later on in the book.</p>
</section>
<section id="validating" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="validating"><span class="header-section-number">4.1.2</span> Validating</h3>
<p>The easiest way to think about the validation dataset is by thinking about what it is <em>not</em> used for: training the model (this is the training set), and giving a final overview of the model expected performance (this is the testing set). The validation set is used for everything else (model selection, cross-validation, hyper-parameters tuning), albeit in a specific way. With the training set, we communicate the predictors and the labels to the model, and update the weights of the model in response. With the validation set, we communicate the predictors and the labels to the model, but we do <em>not</em> update the weights in response. All we care about during validation is the performance of the model on a problem it has not yet encountered during training. If the training set is like attending a lecture, the validation set is like formative feedback.</p>
<p>Of course, one issue with the creation of a validation set is that it needs to resemble the problem the model will have to solve in practice. We will discuss this more in depth in the following sections, but it is worth thinking about an example. Assume a model that classifies a picture as having either a black bear, or no black bear. Now, we can train this model using, for example, images from 10 camera traps that are situated in a forest. And we might want to validate with a camera trap that is in a zoo. In one of the enclosures. The one with a bear. A polar one.</p>
<p>The issue with this dataset as a validation dataset is that is does not matches the problem we try to solve in many different ways. First, we will have an excess of images with bears compared to our problem environment. Second, the data will come from very different environments (forest v. zoo). Finally, we are attempting to validate on something that is an entirely different species of bear. This sounds like an egregious case (it is), but it is easy to commit this type of mistake when our data get more complex than black bear, polar bear, no bear.</p>
<p>Validation is, in particular, very difficult when the dataset we use for training has extreme events <span class="citation" data-cites="bellocchi2010">(<a href="../references.html#ref-bellocchi2010" role="doc-biblioref">Bellocchi <em>et al.</em> 2010</a>)</span>. Similarly, the efficiency of validation datasets can be limited if it reflects the same biases as the training data <span class="citation" data-cites="martinez-meyer2005">(<a href="../references.html#ref-martinez-meyer2005" role="doc-biblioref">Martinez-Meyer 2005</a>)</span>. Recall that this validation dataset is used to decide on the ideal conditions to train the final model before testing (and eventually, deployment); it is, therefore, extremely important to get it right. A large number of techniques to split data <strong>REF TK</strong> use heuristics to minimize the risk of picking the wrong validation data.</p>
</section>
<section id="testing" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="testing"><span class="header-section-number">4.1.3</span> Testing</h3>
<p>The testing dataset is special. The model has <em>never</em> touched it. Not during training, and not for validation. For this reason, we can give it a very unique status: it is an analogue to data that are newly collected, and ready to be passed through the trained model in order to make a prediction. The only difference between the testing set and actual new data is that, for the testing set, we know the labels. In other words, we can compare the model output to these labels, and this gives us an estimate of the model performance on future data.</p>
<p>But this requires a trained model, and we sort of glossed over this step. In order to come up with a trained model, it would be a strange idea not to use the validation data – they are, after all, holding information about the data we want to model! Once we have evaluated our model on the validation set, we can start the last round of training to produce the final model. We do this by training the model using everything <em>except</em> the testing data.</p>
</section>
</section>
<section id="the-problem-phenology-of-cherry-blossom" class="level2 page-columns page-full" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="the-problem-phenology-of-cherry-blossom"><span class="header-section-number">4.2</span> The problem: phenology of cherry blossom</h2>
<p>The cherry blossom tree (<em>Prunus</em>) is …</p>
<p>Long-term time series of the date of first bloom in Japan reveal that in the last decades, cherry blossom blooms earlier, which has been linked to, possibly, climate change and urbanization. The suspected causal mechanism is as follows: both global warming and urbanization lead to higher temperatures, which means a faster accumulation of degree days over the growing season, leading to an earlier bloom. Indeed, the raw data presented in <a href="#fig-splits-rawdata" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> show that trees bloom early when the temperatures are higher.</p>
<div class="quarto-embed-nb-cell page-columns page-full" data-notebook="/home/tpoisot/Manuscripts/biodiversitymlfundamentals/notebooks/sm-splits.qmd" data-notebook-title="An analysis of the sakura phenology dataset" data-notebook-cellid="cell-fig-splits-rawdata">
<div id="cell-fig-splits-rawdata" class="cell page-columns page-full" data-execution_count="4">
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-splits-rawdata" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="splits_files/figure-html/fig-splits-rawdata-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;4.1: The raw data show a negative relationship between the temperature in March, and the bloom time. This suggests that when the trees have accumulated enough temperature, they can bloom early. In a context of warming, we should therefore see earlier blooms with rising temperatures.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>With these data in hand (day of year with the first bloom, and smoothed reconstructed temperature in March), we can start thinking about this hypothesis. But by contrast with our simple strategy in <strong>GRADIENT</strong>, this time, we will split our dataset into training, validation, and testing sets, as we discussed in the previous section. Yet there are many ways to split a dataset, and therefore before starting the analysis, we will have a look at a few of them.</p>
</section>
<section id="strategies-to-split-data" class="level2 page-columns page-full" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="strategies-to-split-data"><span class="header-section-number">4.3</span> Strategies to split data</h2>
<p>remove testing first if needed</p>
<p>exhaustive</p>
<p>non-exhaustive</p>
<section id="holdout" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="holdout"><span class="header-section-number">4.3.1</span> Holdout</h3>
<p>The holdout method is what we used in <strong>TODO REF GRAD</strong>, in which we randomly selected some observations to be part of the validation data (which was, in practice, a testing dataset in this example), and kept the rest to serve as the training data. Holdout cross-validation is possibly the simplest technique, but it suffers from a few drawbacks.</p>
<p>The model is only trained for one split of the data, and similarly only evaluated for one split of the data. There is, therefore, a chance to sample a particularly bad combination of the data that lead to erroneous results. Attempts to quantify the importance of the predictors are likely to give particularly unstable results, as the noise introduced by picking a single random subset will not be smoothed out by multiple attempts.</p>
<p>In addition, as <span class="citation" data-cites="hawkins2003">Hawkins <em>et al.</em> (<a href="../references.html#ref-hawkins2003" role="doc-biblioref">2003</a>)</span> point out, holdout validation is particularly wasteful in data-limited settings, where there are fewer than hundreds of observations. The reason is that the holdout dataset will <em>never</em> contribute to training, and assuming the data are split 80/20, one out of five observations will not contribute to the model. Other cross-validation schemes presented in this section will allow observations to be used both for training and validation.</p>
</section>
<section id="leave-p-out" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="leave-p-out"><span class="header-section-number">4.3.2</span> Leave-p-out</h3>
<p>In leave-<em>p</em>-out cross-validation (LpOCV), starting from a dataset on <span class="math inline">\(n\)</span> observation, we pick <span class="math inline">\(p\)</span> at random to serve as validation data, and <span class="math inline">\(n-p\)</span> to serve as the training dataset. This process is then repeated <em>exhaustively</em>, which is to say we split the dataset in every possible way that gives <span class="math inline">\(p\)</span> and <span class="math inline">\(n-p\)</span> observations, for a set value of <span class="math inline">\(p\)</span>. The model is then trained on the <span class="math inline">\(n-p\)</span> observations, and validated on the <span class="math inline">\(p\)</span> observations for validation, and the performance (or loss) is averaged to give the model performance before testing.</p>
<p><span class="citation" data-cites="celisse2014">Celisse (<a href="../references.html#ref-celisse2014" role="doc-biblioref">2014</a>)</span> points out that <span class="math inline">\(p\)</span> has to be large enough (relative to the sample size <span class="math inline">\(n\)</span>) to overcome the propensity of the model to overfit on a small training dataset. One issue with LpOCV is that the number of combinations is potentially very large. It is, in fact, given by the binomial coefficent <span class="math inline">\(\binom{n}{p}\)</span>, which gets unreasonably large even for small datasets. For example, running LpOCV on <span class="math inline">\(n=150\)</span> observations, leaving out <span class="math inline">\(p=10\)</span> for validation everytime, would require to train the model about <span class="math inline">\(10^{15}\)</span> times. Assuming we can train the model in <span class="math inline">\(10^{-3}\)</span> seconds, the entire process would require 370 centuries.</p>
<p>Oh well.</p>
</section>
<section id="leave-one-out" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="leave-one-out"><span class="header-section-number">4.3.3</span> Leave-one-out</h3>
<p>The leave-one-out cross-validation (LOOCV) is a special case of LpOCV with <span class="math inline">\(p=1\)</span>. Note that it is a lot faster to run than LpOCV, because <span class="math inline">\(\binom{n}{1}=n\)</span>, and so the validation step runs in <span class="math inline">\(\mathcal{O}(n)\)</span> (LpOCV runs in <span class="math inline">\(\mathcal{O}(n!)\)</span>). LOOCV is also an <em>exhaustive</em> cross-validation technique, as every possible way to split the dataset will be used for training and evaluation.</p>
</section>
<section id="k-fold" class="level3 page-columns page-full" data-number="4.3.4">
<h3 data-number="4.3.4" class="anchored" data-anchor-id="k-fold"><span class="header-section-number">4.3.4</span> k-fold</h3>
<p>One of the most frequent cross-validation scheme is k-fold cross-validation. Under this approach, the dataset is split into <span class="math inline">\(k\)</span> equal parts (and so when <span class="math inline">\(k = n\)</span>, this is also equivalent to LOOCV). Like with LOOCV, one desirable property of k-fold cross-validation is that each observation is used <em>exactly</em> one time to evaluate the model , and <em>exactly</em> <span class="math inline">\(k-1\)</span> times to train it. But by contrast with the holdout validation approach, <em>all</em> observations are used to train the model.</p>
<p>When the data have some specific structure, it can be a good thing to manipulate the splits in order to maintain this structure. For example, <span class="citation" data-cites="bergmeir2012">Bergmeir &amp; Benítez (<a href="../references.html#ref-bergmeir2012" role="doc-biblioref">2012</a>)</span> use temporal blocks for validation of time series, and retain the last part of the series for testing (we illustrate this in <a href="#fig-splits-illustration" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>). For spatial data, <span class="citation" data-cites="hijmans2012">Hijmans (<a href="../references.html#ref-hijmans2012" role="doc-biblioref">2012</a>)</span> suggests the use of a null model based on distance to training sites to decide on how to split the data; <span class="citation" data-cites="valavi2018">Valavi <em>et al.</em> (<a href="../references.html#ref-valavi2018" role="doc-biblioref">2018</a>)</span> have designed specific k-fold cross-validation schemes for species distribution models. These approaches all belong to the family of <em>stratified</em> k-fold cross-validation <span class="citation" data-cites="zeng2000">(<a href="../references.html#ref-zeng2000" role="doc-biblioref">Zeng &amp; Martinez 2000</a>)</span>.</p>
<div class="quarto-embed-nb-cell page-columns page-full" data-notebook="/home/tpoisot/Manuscripts/biodiversitymlfundamentals/notebooks/sm-splits.qmd" data-notebook-title="An analysis of the sakura phenology dataset" data-notebook-cellid="cell-fig-splits-illustration">
<div id="cell-fig-splits-illustration" class="cell page-columns page-full" data-execution_count="7">
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-splits-illustration" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="splits_files/figure-html/fig-splits-illustration-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;4.2: An illustration of a series of folds on a timeseries. The grey aata are used for training, the black data for validation, and the red data are kept for testing. Note that in this context, we sometimes use the future to validate on the past (look at the first fold!), but this is acceptable for reasons explained in the text.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>The appropriate value of <span class="math inline">\(k\)</span> is often an unknown. It is common to use <span class="math inline">\(k = 10\)</span> as a starting point (tenfold cross-validation), but other values are justifiable based on data volume, complexity of the model training, to name a few.</p>
</section>
<section id="monte-carlo" class="level3" data-number="4.3.5">
<h3 data-number="4.3.5" class="anchored" data-anchor-id="monte-carlo"><span class="header-section-number">4.3.5</span> Monte-Carlo</h3>
<p>One of the limitations of k-fold cross-validation is that the number of splits is limited by the amount of observations, especially if we want to ensure that there are enough samples in the validation data. To compensate for this, Monte-Carlo cross-validation is essentially the application (and averaging) of holdout validation an arbitrary number of times. Furthermore, the training and validation datasets can be constructed in order to account for specific constraints in the dataset, giving more flexibility than k-fold cross-validation. When the (computational) cost of training the model is high, and the dataset has specific structural constraints, Monte-Carlo cross-validation is a good way to generate data for hyperparameters tuning.</p>
<p>One issue with Monte-Carlo cross-validation is that we lose the guarantee that every observation will be used for training at least once (and similarly for validation). Trivially, this becomes less of an issue when we increase the number of replications, but then this suffers from the same issues as LpOCV, namely the unreasonable computational requirements.</p>
</section>
</section>
<section id="application-when-do-cherry-blossom-bloom" class="level2 page-columns page-full" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="application-when-do-cherry-blossom-bloom"><span class="header-section-number">4.4</span> Application: when do cherry blossom bloom?</h2>
<p>The model we will train for this section is really simple: <span class="math inline">\(\text{bloom day} = m \times \text{temperature} + b\)</span>. This is a linear model, and one with a nice, direct biological interpretation: the average (baseline) day of bloom is <span class="math inline">\(b\)</span>, and each degree adds <span class="math inline">\(m\)</span> days to the bloom date. At this point, we <em>might</em> start thinking about the distribution of the response, and what type of GLM we should used, but no. Not today. Today, we want to iterate quickly, and so we will start with a model that is exactly as simple as it needs to be.</p>
<p>This approach (start from a model that is suspiciously simple) is a good thing, for more than a few reasons. First, it gives us a baseline to compare more complicated models against. Second, it means that we do not need to focus on the complexity of the code (and the model) when building a pipeline for the analysis. Finally, and most importantly, it gives us a result very rapidly, which enables a loop of iterative model refinement on a very short timescale. Additionally, at least for this example, the simple models often work rather well.</p>
<section id="performance-evaluation" class="level3 page-columns page-full" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="performance-evaluation"><span class="header-section-number">4.4.1</span> Performance evaluation</h3>
<p>We can visualize the results of our model training and assessment process. These results are presented in <a href="#fig-splits-performance" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> (as well as in <a href="#tbl-splits-performance-summary" class="quarto-xref">Table&nbsp;<span>4.2</span></a>, if you want to see the standard deviation across all splits), and follow the same color-coding convention we have used so far. All three loss measures presented here express their loss in the units of the response variable, which in this case is the day of the year where the bloom was recorded. These results show that our trained model achieves a loss of the order of a day or two in the testing data, which sounds really good!</p>
<div class="quarto-embed-nb-cell page-columns page-full" data-notebook="/home/tpoisot/Manuscripts/biodiversitymlfundamentals/notebooks/sm-splits.qmd" data-notebook-title="An analysis of the sakura phenology dataset" data-notebook-cellid="cell-fig-splits-performance">
<div id="cell-fig-splits-performance" class="cell page-columns page-full" data-execution_count="15">
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-splits-performance" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="splits_files/figure-html/fig-splits-performance-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;4.3: Visualisation of the model performance for …. The colors are the same as in fig-splits-illustration, <em>i.e.</em> grey for the training data, green for the validation data, and purple for the testing data.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Yet it is important to contextualize these results. What does it means for our prediction to be correct plus or minus two days? There are at least two important points to consider.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/tpoisot/Manuscripts/biodiversitymlfundamentals/notebooks/sm-splits.qmd" data-notebook-title="An analysis of the sakura phenology dataset" data-notebook-cellid="cell-tbl-splits-performance-summary">
<div class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<div id="tbl-splits-performance-summary" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;4.2: TODO</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Dataset</th>
<th style="text-align: right;">Measure</th>
<th style="text-align: right;">Loss (avg.)</th>
<th style="text-align: right;">Loss (std. dev.)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">MAE</td>
<td style="text-align: right;">1.696</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">MAE</td>
<td style="text-align: right;">2.2397</td>
<td style="text-align: right;">0.0482364</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">MAE</td>
<td style="text-align: right;">2.26331</td>
<td style="text-align: right;">0.421513</td>
</tr>
<tr class="even">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">MBE</td>
<td style="text-align: right;">0.0971036</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">MBE</td>
<td style="text-align: right;">9.8278e-15</td>
<td style="text-align: right;">1.15597e-14</td>
</tr>
<tr class="even">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">MBE</td>
<td style="text-align: right;">0.000419595</td>
<td style="text-align: right;">0.910229</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">MSE</td>
<td style="text-align: right;">4.49123</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">MSE</td>
<td style="text-align: right;">8.04855</td>
<td style="text-align: right;">0.32487</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">MSE</td>
<td style="text-align: right;">8.24897</td>
<td style="text-align: right;">2.93094</td>
</tr>
<tr class="even">
<td style="text-align: right;">Testing</td>
<td style="text-align: right;">RMSE</td>
<td style="text-align: right;">2.11925</td>
<td style="text-align: right;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">Training</td>
<td style="text-align: right;">RMSE</td>
<td style="text-align: right;">2.83648</td>
<td style="text-align: right;">0.0570941</td>
</tr>
<tr class="even">
<td style="text-align: right;">Validation</td>
<td style="text-align: right;">RMSE</td>
<td style="text-align: right;">2.82514</td>
<td style="text-align: right;">0.545232</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<p>First, what are we predicting? Our response variable is not <em>really</em> the day of the bloom, but is rather a smoothed average looking back some years, and looking ahead some years too. For this reason, we are removing a lot of the variability in the underlying time series. This is not necessarily a bad thing, especially if we are looking for a trend at a large temporal scale, but it means that we should not interpret our results at a scale lower than the duration of the window we use for averaging.</p>
<p>Second, what difference <em>does</em> a day make? <a href="#fig-splits-rawdata" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> shows that most of the days of bloom happen between day-of-year 100 and day-of-year 110. Recall that the MAE is measured by taking the average absolute error – a mistake of 24 hours is 10% of this interval! This is an example of how thinking about the units of the loss function we use for model evaluations can help us contextualize the predictions.</p>
</section>
<section id="model-predictions" class="level3 page-columns page-full" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="model-predictions"><span class="header-section-number">4.4.2</span> Model predictions</h3>
<p>The predictions of our model are presented in <a href="#fig-splits-prediction" class="quarto-xref">Figure&nbsp;<span>4.4</span></a>; these are the predictions of the <em>final</em> model, that is, the model that we trained on everything <em>except</em> the testing data, and for which we can get the performance by looking at <a href="#fig-splits-performance" class="quarto-xref">Figure&nbsp;<span>4.3</span></a>.</p>
<div class="quarto-embed-nb-cell page-columns page-full" data-notebook="/home/tpoisot/Manuscripts/biodiversitymlfundamentals/notebooks/sm-splits.qmd" data-notebook-title="An analysis of the sakura phenology dataset" data-notebook-cellid="cell-fig-splits-prediction">
<div id="cell-fig-splits-prediction" class="cell page-columns page-full" data-execution_count="12">
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-splits-prediction" class="quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="splits_files/figure-html/fig-splits-prediction-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Figure&nbsp;4.4: TODO</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>The question we now need to answer is: is our model doing a good job? We can start thinking about this question in a very qualitative way: yes, it does a goob job at drawing a line that, through time, goes right through the original data. As far as validation goes, it maybe underestimates the drop in the response variable (it predicts the bloom a little later), but maybe there are long-term effects, expressed over the lifetime of the tree (the first bloom usually takes places after 6 or 7 growth seasons), that we do not account for.</p>
<p>Our model tends to smooth out some of the variation; it does not predict bloom dates before day of year 100, or after day of year 108, although they do happen. This may not be a trivial under-prediction: some of these cycles leading to very early/late bloom can take place over a century, meaning that our model could be consistently wrong (which is to say, wrong with the same bias) for dozens of years in a row.</p>
</section>
<section id="sec-splits-fitness" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="sec-splits-fitness"><span class="header-section-number">4.4.3</span> Is our model good, then?</h3>
<p>The answer is, it depends. Models are neither good, nor bad. They are either fit, or unfit, for a specific purpose.</p>
<p>If the purpose is to decide when to schedule a one-day trip to see the cherry blossom bloom, our model is not really fit – looking at the predictions, it gets within a day of the date of bloom (but oh, by the way, this is an average over close to a decade!) about 15% of the time, which jumps up to close to 30% if you accept a two-days window of error.</p>
<p>If the purpose is to look at long-time trends in the date of bloom, then our model actually works rather well. It does under-estimate the amplitude of the cycles, but not by a large amount. In fact, we could probably stretch the predictions a little, applying a little correction factor, and have a far more interesting model.</p>
<p>We will often be confronted to this question when working with prediction. There is not really a criteria for “good”, only a series of compromises and judgment calls about “good enough”. This is important. It reinforces the imperative of keeping the practice of data science connected to the domain knowledge, as ultimately, a domain expert will have to settle on whether to use a model or not.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-bellocchi2010" class="csl-entry" role="listitem">
Bellocchi, G., Rivington, M., Donatelli, M. &amp; Matthews, K. (2010). <a href="https://doi.org/10.1051/agro/2009001">Validation of biophysical models: issues and methodologies. A review</a>. <em>Agronomy for Sustainable Development</em>, 30, 109–130.
</div>
<div id="ref-bergmeir2012" class="csl-entry" role="listitem">
Bergmeir, C. &amp; Benítez, J.M. (2012). <a href="https://doi.org/10.1016/j.ins.2011.12.028">On the use of cross-validation for time series predictor evaluation</a>. <em>Information Sciences</em>, 191, 192–213.
</div>
<div id="ref-celisse2014" class="csl-entry" role="listitem">
Celisse, A. (2014). <a href="https://doi.org/10.1214/14-aos1240">Optimal cross-validation in density estimation with the <span>$</span>l<span>^</span><span></span>2<span></span><span>$</span>-loss</a>. <em>The Annals of Statistics</em>, 42.
</div>
<div id="ref-hawkins2003" class="csl-entry" role="listitem">
Hawkins, D.M., Basak, S.C. &amp; Mills, D. (2003). <a href="https://doi.org/10.1021/ci025626i">Assessing Model Fit by Cross-Validation</a>. <em>Journal of Chemical Information and Computer Sciences</em>, 43, 579–586.
</div>
<div id="ref-hijmans2012" class="csl-entry" role="listitem">
Hijmans, R.J. (2012). <a href="https://doi.org/10.1890/11-0826.1">Cross-validation of species distribution models: removing spatial sorting bias and calibration with a null model</a>. <em>Ecology</em>, 93, 679–688.
</div>
<div id="ref-martinez-meyer2005" class="csl-entry" role="listitem">
Martinez-Meyer, E. (2005). <a href="https://doi.org/10.17161/bi.v2i0.8">Climate change and biodiversity: Some considerations in forecasting shifts in species’ potential distributions</a>. <em>Biodiversity Informatics</em>, 2.
</div>
<div id="ref-valavi2018" class="csl-entry" role="listitem">
Valavi, R., Elith, J., Lahoz-Monfort, J.J. &amp; Guillera-Arroita, G. (2018). <a href="https://doi.org/10.1111/2041-210x.13107">block CV : An r package for generating spatially or environmentally separated folds for <span><em>k</em></span> <span>-</span>fold cross<span>-</span>validation of species distribution models</a>. <em>Methods in Ecology and Evolution</em>, 10, 225–232.
</div>
<div id="ref-zeng2000" class="csl-entry" role="listitem">
Zeng, X. &amp; Martinez, T.R. (2000). <a href="https://doi.org/10.1080/095281300146272">Distribution-balanced stratified cross-validation for accuracy estimation</a>. <em>Journal of Experimental &amp; Theoretical Artificial Intelligence</em>, 12, 1–12.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        console.log("RESIZE");
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>This work is licensed under the <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 International License</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>