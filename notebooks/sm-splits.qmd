---
title: An analysis of the sakura phenology dataset
---

This notebook is used to support the chapter on data splitting. This notebook has a little more content compared to the chapter, as we will train and compare two different models.

```{julia}
using DataFrames
import CSV
using Statistics
using GLM
using CairoMakie
using Markdown
using MarkdownTables
CairoMakie.activate!(; px_per_unit = 2)
```

We first load the data. The data as presented here have a column for the temperature in March, which has been smoothed, and for the day of bloom, which is expressed as day of year:

```{julia}
sakura = DataFrame(CSV.File(joinpath(@__DIR__, "..", "data", "general", "sakura.csv")))
allowmissing!(sakura, :temperature)
replace!(sakura.temperature, -50.0 => missing)
sort!(sakura, :year)
describe(sakura)
```

We will use a running average for the date of bloom; this is a little artificial, but it ensures that we smooth out the differences from year to year. The size of the window is, in a sense, a parameter of the model (or at least a parameter of the data preparation process) that we may want to tweak.

```{julia}
average = zeros(Float64, size(sakura, 1))
for (i, row) in enumerate(eachrow(sakura))
    window = sort((-7, 2))
    year_span = row.year .+ window
    valid_records = year_span[1] .< sakura.year .< year_span[2]
    subset = dropmissing(sakura[findall(valid_records), :])
    if size(subset, 1) >= 3
        average[i] = mean(subset.flowering)
    end
end
sakura.flowavg = average

allowmissing!(sakura, :flowavg)
replace!(sakura.flowavg, 0.0 => missing)

dropmissing!(sakura)
```

We can inspect the data to look for a linear relationship between temperature and flowering time:

```{julia}
#| label: fig-splits-rawdata
#| fig-cap: The raw data show a negative relationship between the temperature in March, and the bloom time. This suggests that when the trees have accumulated enough temperature, they can bloom early. In a context of warming, we should therefore see earlier blooms with rising temperatures.
f = Figure(; resolution=(500, 300))
ax = Axis(f[1,1]; xlabel="March temperature (Â°C)", ylabel="Bloom time (day of year)")
scatter!(ax, sakura.temperature, sakura.flowering, color=:lightgrey)
current_figure()
```

We can now define a few loss functions to compare them later on:

```{julia}
mse(tr, pr) = mean((tr .- pr).^2.0)
rmse(tr, pr) = sqrt(mse(tr, pr))
mae(tr, pr) = mean(abs.(tr .- pr))
mbe(tr, pr) = mean(tr .- pr)
```

We now define a series of folds, in order to do k-folds cross validation. Note that we keep a holdout test dataset corresponding to the end of the time series for model evaluation.

```{julia}
n = size(sakura, 1)
test_size = ceil.(Int, 0.25n)

sakuratrain = sakura[1:(n-test_size), :]
sakuratest = sakura[(n-test_size+1):n, :]

folds = ceil.(Int, LinRange(1, size(sakuratrain, 1), 11))
```

This next figure is purely an illustration of the splits:

```{julia}
#| label: fig-splits-illustration
#| fig-cap: An illustration of a series of folds on a timeseries. The grey aata are used for training, the black data for validation, and the red data are kept for testing. Note that in this context, we sometimes use the future to validate on the past (look at the first fold!), but this is acceptable for reasons explained in the text.
f = Figure()
s1 = Axis(f[1,1])
s2 = Axis(f[2,1])
s3 = Axis(f[3,1])
s4 = Axis(f[4,1])
for (i,s) in enumerate([s1, s2, s3, s4])
    scatter!(s, sakuratrain.year, sakuratrain.flowavg, color=:lightgrey)
    scatter!(s, sakuratest.year, sakuratest.flowavg, color=Makie.wong_colors()[4], linewidth=4)
    j = 2i-1
    valid_idx = folds[j]:folds[j+1]
    train_idx = filter(n -> !(n in valid_idx), 1:size(sakuratrain, 1))
    valid = sakuratrain[valid_idx, :]
    train = sakuratrain[train_idx, :]
    scatter!(s, valid.year, valid.flowavg, color=Makie.wong_colors()[3], linewidth=2)
    hidedecorations!(s)
    hidespines!(s)
end
current_figure()
```

placeholders for validation measures

```{julia}
test_results = DataFrame()
```

this is the cross validation

```{julia}
for (i, Ki) in enumerate(folds)
    if Ki < size(sakuratrain, 1)
        valid_idx = folds[i]:folds[i+1]
        train_idx = filter(n -> !(n in valid_idx), 1:size(sakuratrain, 1))
        valid = sakuratrain[valid_idx, :]
        train = sakuratrain[train_idx, :]
        m1 = lm(@formula(flowavg ~ temperature), train)
        m2 = lm(@formula(flowavg ~ temperature + temperature^-1), train)
        for (md, mn) in [(m1, :Simple), (m2, :Inverse)]
            for (ds, dn) in [(train, :Training), (valid, :Validation)]
                for (m,p) in [(mse, :MSE), (rmse, :RMSE), (mae, :MAE), (mbe, :MBE)]
                    loss = m(ds.flowavg, predict(md, ds))
                    push!(test_results,
                        (
                            Model = mn,
                            Dataset = dn,
                            Measure = p,
                            Value = loss
                        )
                    )
                end
            end
        end
    end
end

gr_test = groupby(test_results, [:Model, :Dataset, :Measure])
benchmark_result = combine(gr_test, :Value => mean => Symbol("Loss (avg.)"), :Value => std => Symbol("Loss (std. dev.)"))
sort!(benchmark_result, [:Measure, :Dataset, :Model, Symbol("Loss (avg.)")])
```

Based on these results, we can look at the value of the MAE loss to pick our best model:

```{julia}
choice = benchmark_result[(benchmark_result.Measure .== :MAE),:]
sort!(choice, :Dataset)
```

It looks like the models with additional terms do not work any better than a simple regression against the temperature, so we will select the simpler model. We now train the model on the full dataset:

```{julia}
model = lm(@formula(flowavg ~ temperature), sakuratrain)
```

```{julia}
#| label: fig-splits-prediction
#| fig-cap: TODO
f = Figure(; resolution=(500, 300))
ax = Axis(f[1,1]; xlabel="Year", ylabel="Day of bloom")
scatter!(ax, sakura.year, sakura.flowavg, color=:lightgrey, markersize=6)
lines!(ax, sakuratrain.year, predict(model, sakuratrain), color=:black, linewidth=1)
lines!(ax, sakuratest.year, predict(model, sakuratest), color=Makie.wong_colors()[4], linewidth=2)
current_figure()
```

We can now make a table with the results (by dataset/loss function):

```{julia}
summary_table = benchmark_result[benchmark_result.Model .== :Simple, :]
select!(summary_table, Not(:Model))
select!(summary_table, Not(Symbol("Loss (std. dev.)")))
for (m,p) in [(mse, :MSE), (rmse, :RMSE), (mae, :MAE), (mbe, :MBE)]
    loss = m(sakuratest.flowavg, predict(model, sakuratest))
    push!(summary_table,
        (
            :Testing, p, loss,
        )
    )
end
sort!(summary_table, [:Measure, :Dataset])
```

We will turn this into a little visualisation, to get a sense of what the measures say:

```{julia}
#| label: fig-splits-performance
#| fig-cap: Visualisation of the model performance for .... The colors are the same as in fig-splits-illustration, *i.e.* grey for the training data, green for the validation data, and purple for the testing data.
f = Figure(; resolution=(500, 300))
model_results = test_results[test_results.Model .== :Simple, :]
for (i,m) in enumerate([:MAE, :RMSE, :MBE])
    ax = Axis(f[i,1]; ylabel=String(m))
    ylims!(ax, (-0.15, 0.15))
    hidespines!(ax, :l, :r, :t)
    hideydecorations!(ax, label=false)
    hidexdecorations!(ax, grid=true, ticks=false, ticklabels=false)
    thesedata = model_results[model_results.Measure .== m, :]
    traindata = thesedata[thesedata.Dataset .== :Training, :]
    scatter!(ax, traindata.Value, fill(0.1, size(traindata, 1)), color=:lightgrey)
    validdata = thesedata[thesedata.Dataset .== :Validation, :]
    scatter!(ax, validdata.Value, fill(-0.1, size(validdata, 1)), color=Makie.wong_colors()[3])
    testdata = summary_table[(summary_table.Dataset .== :Testing).&(summary_table.Measure .== m), :]
    rename!(testdata, Symbol("Loss (avg.)") => :Value)
    scatter!(ax, only(testdata.Value), 0.0, color=Makie.wong_colors()[4], marker=:diamond, markersize=14)
end
current_figure()
```

Finally, we can take a look at the prediction of the model but only looking at the testing dataset:

```{julia}
#| label: fig-splits-detail
#| fig-cap: TODO
f = Figure()
ax = Axis(f[1,1])
scatter!(ax, sakuratest.year, sakuratest.flowavg, color=:lightgrey)
lines!(ax, sakuratest.year, predict(model, sakuratest), color=:red)
current_figure()
```

one-day trip

```{julia}
(count(sort(abs.(predict(model, sakura) .- sakura.flowavg)) .< 0.5) / size(sakura, 1))*100
```

stretching for in-class demo

```{julia}
pred = predict(model, sakura)
truth = sakura.flowavg
mpred = (pred .- mean(pred)) .* 1.9 .+ mean(pred)
scatter(sakura.year, sakura.flowavg)
scatter!(sakura.year, mpred)
current_figure()
```